{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch-GPU",
      "language": "python",
      "name": "pyt-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pDnSshCXD-ZL",
        "2JDTirUfD-Zf",
        "vICVTE1wD-Zq",
        "wDNQLaL6D-Zu",
        "hNbj9oDlD-aS",
        "3kRdaQe6D-ab",
        "5t7iYj2eD-an",
        "tRlkcpT0D-a1",
        "ROmpaSMVD-bA",
        "VY6m7c0qD-bQ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneway-net/scientific-python/blob/main/Lecture_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VNIH93hD-Ya"
      },
      "source": [
        "# Lecture 8 - PyTorch\n",
        "\n",
        "This will be the final lecture, today we will first have a brief introduction of deep learning, then we will look at some basics of using PyTorch to implement some simple models in deep learning.\n",
        "\n",
        "1. Homework due today\n",
        "2. No OH today"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Section (Start)\n",
        "What is Neural Network:\n",
        "1. [My recommended youtube video with great visual helpers](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=4)\n",
        "2.  [Previous Years Instructor's Recording](https://stanford-pilot.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=c79271d9-3694-49d3-8f93-afb10161e47e)\n",
        "# Basic Section (End)"
      ],
      "metadata": {
        "id": "jJYsdl4IbsO6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fCZYu2D-Yc"
      },
      "source": [
        "## Deep Learning Libraries\n",
        "\n",
        "There are many deep learning libraries available, the most common ones for python are\n",
        "\n",
        "- TensorFlow, Keras\n",
        "- PyTorch\n",
        "\n",
        "Working with tensorflow requires going into lot of details of the contruction of the computation graph, whereas Keras is a higher level interface for tensorflow. Tensorflow is very popular in the industry and good for production code.\n",
        "\n",
        "PyTorch can be used as low level interface, but is much more user-friendly than tensorflow, but it also has a higher level interface. Pytorch is more popular in the research community."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUDYHi8D-Yd"
      },
      "source": [
        "## Main features that any deep learning library should provide\n",
        "\n",
        "No matter what library or language you use, the main features provided by a deep learning library are \n",
        "1. Use the GPU to speed up computation \n",
        "2. Ability to do automatic differentiation\n",
        "3. Useful library functions for common architectures and optimization algorithms\n",
        "\n",
        "### PyTorch\n",
        "We will look at all of the above in pytorch.\n",
        "The best way to think about pytorch is that its numpy + GPU + autograd.\n",
        "\n",
        "You can install it with\n",
        "\n",
        "```conda install pytorch```.\n",
        "\n",
        "Alternatively (and recommended), run this notebook in Google Colab-- it provides an environment with all of the PyTorch dependencies plus a GPU free of charge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCdvNHW0D-Ye"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpWzZewHD-Yi"
      },
      "source": [
        "The equivalent object to numpy arrays in pytorch are called tensors, but they are just multidimensional arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t78yenP1D-Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0c461e-703f-46df-98ef-b10e038aba64"
      },
      "source": [
        "torch.tensor([2,3,4,5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efg1UeizD-Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4056dc5-a957-4c02-d164-ce49a0d16526"
      },
      "source": [
        "torch.zeros((5,5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BlufhDpD-Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1283aace-d534-4267-a874-68e962ff36c3"
      },
      "source": [
        "x = torch.ones((5,5))\n",
        "print(type(x))\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acgFdW_4D-Yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d86c59-3c4d-4e62-8b3f-afe40c793c80"
      },
      "source": [
        "2*x + 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwCz7O1wD-Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c4ce65-d9e6-4e14-ba95-2f834168b758"
      },
      "source": [
        "torch.randn(5,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0389,  1.9222, -0.5508,  0.2756, -0.9061],\n",
              "        [-0.3364,  0.6881, -0.0981, -0.5064,  0.0598],\n",
              "        [ 0.2379,  0.6156,  0.2822,  1.9747,  1.4114],\n",
              "        [-2.4697,  0.7823,  1.2714, -0.9148, -0.4484],\n",
              "        [-0.5442, -1.9438,  1.1559,  0.8419,  0.7047]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fHiY5VKD-Yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faddb0a6-4970-4046-ce9f-161fcbf82251"
      },
      "source": [
        "x = torch.rand(25)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6136, 0.2190, 0.5721, 0.6396, 0.6953, 0.4541, 0.3827, 0.0567, 0.6638,\n",
              "        0.7713, 0.1073, 0.1899, 0.6161, 0.4600, 0.9465, 0.1657, 0.6050, 0.0697,\n",
              "        0.7622, 0.8850, 0.6074, 0.1173, 0.3420, 0.9066, 0.6158])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_QKyI7hD-Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64a413d-8ccd-498d-9289-900a4e07dc9a"
      },
      "source": [
        "x=x.reshape(-1,5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6136, 0.2190, 0.5721, 0.6396, 0.6953],\n",
              "        [0.4541, 0.3827, 0.0567, 0.6638, 0.7713],\n",
              "        [0.1073, 0.1899, 0.6161, 0.4600, 0.9465],\n",
              "        [0.1657, 0.6050, 0.0697, 0.7622, 0.8850],\n",
              "        [0.6074, 0.1173, 0.3420, 0.9066, 0.6158]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLKjs14-D-Y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b27f41-20e5-41c5-ae62-13de4716b2b7"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9fwJoSD-Y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22dd433-c8db-4bc3-eb99-3561c866fa9e"
      },
      "source": [
        "print(torch.arange(10))\n",
        "print(torch.eye(5))\n",
        "print(torch.linspace(0,1,10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cix7EXwSD-Y7"
      },
      "source": [
        "Some functions are a bit different"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(5,5)\n",
        "x = np.ones((5,1))\n",
        "A@x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRrYVBDmjLpq",
        "outputId": "1fe4b00d-c01f-4e13-f93d-bd9aa5ffb751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.27711895],\n",
              "       [2.09251975],\n",
              "       [3.38718905],\n",
              "       [2.33932473],\n",
              "       [3.32822249]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_ = torch.rand((5,5))\n",
        "x_ = torch.rand(5,1)\n",
        "A_@x_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npGWD47jicvY",
        "outputId": "ef3e7595-01b3-48cb-934b-4af306b1ed67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7982],\n",
              "        [1.2171],\n",
              "        [1.4513],\n",
              "        [0.8561],\n",
              "        [1.0434]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BukQIL5D-Y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed25451-c49b-4ad3-97e8-1c32c2a97875"
      },
      "source": [
        "A = torch.ones((5,5)) \n",
        "x = torch.ones(5,1)\n",
        "A@x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.],\n",
              "        [5.],\n",
              "        [5.],\n",
              "        [5.],\n",
              "        [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "?np.ones"
      ],
      "metadata": {
        "id": "n2XG-EU0jUci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YHvvy4D-Y-"
      },
      "source": [
        "?torch.ones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpEwcH-JD-ZA"
      },
      "source": [
        "You can convert tensors to a numpy array that shares its memory with the pytorch tensor -> to use more library that are compatible to numpy but not pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MquNPK71D-ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6c7b31-93bc-4dd3-a744-efd2bf390a12"
      },
      "source": [
        "x = torch.ones(5,5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOeMqFrOD-ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fef712-a1fc-4e14-a65c-c0ac6286b918"
      },
      "source": [
        "xn = x.numpy()\n",
        "print(type(xn))\n",
        "xn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlG0x9xD-ZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77342c19-163c-4eab-ca69-ef013213914f"
      },
      "source": [
        "# Changes in Numpy will cause changes in Tensor\n",
        "xn[4,2]=10\n",
        "xn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1., 10.,  1.,  1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6qJIsID-ZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4a24cc-1239-48b2-f5ed-5b30dc44be50"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1., 10.,  1.,  1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDnSshCXD-ZL"
      },
      "source": [
        "### Using the GPU\n",
        "\n",
        "The GPU (Graphical Processing Unit) is a separate processing unit that is specialized to handle bulk computations required for rendering high quality graphics. It mainly consists of a large number of processor cores that are individually very slow, but because of their sheer number (around 2000) they can churn through computations very quickly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmJ0hjO5D-ZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7b4ec5-1b66-4aaa-94f4-d09b553cf189"
      },
      "source": [
        "import torch\n",
        "\"\"\"\n",
        "CUDA is a parallel computing platform \n",
        "and application programming interface \n",
        "that allows software to use certain types \n",
        "of graphics processing units for general purpose processing\n",
        "\"\"\";\n",
        "#CUDA -> Recommend CME213 (C++)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0kadMeJD-ZN"
      },
      "source": [
        "Installing the GPU drivers and the CUDA toolkit can be quite messy, so if you just want to experiment with GPUs and deep learning libraries, you can use [Google colaboratory](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtE0kLaD-ZO"
      },
      "source": [
        "gpu = torch.device(\"cuda\")\n",
        "cpu = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESIE5J08D-ZS"
      },
      "source": [
        "A = torch.rand(100,100)\n",
        "B = torch.rand(100,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6VNz5SzD-ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9bddfa-8d6d-4666-fdd9-ff8cdb7c98a0"
      },
      "source": [
        "A@B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[25.9445, 23.3451, 23.2453,  ..., 23.6876, 23.3642, 21.0127],\n",
              "        [29.1864, 29.7169, 27.8055,  ..., 29.9012, 26.9726, 24.5918],\n",
              "        [26.6460, 26.9354, 25.1543,  ..., 26.0435, 25.1616, 22.4802],\n",
              "        ...,\n",
              "        [29.2716, 27.0511, 27.1193,  ..., 28.7066, 26.1744, 24.4956],\n",
              "        [29.4815, 27.5012, 26.7596,  ..., 29.7794, 28.2612, 25.2685],\n",
              "        [26.5447, 23.0760, 24.2269,  ..., 26.3211, 23.7328, 21.0399]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXjtNNqtD-ZW"
      },
      "source": [
        "A_gpu = A.to(gpu)\n",
        "B_gpu = B.to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krIHa3ErD-ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698cc114-6b74-4379-8e31-10d633d887e9"
      },
      "source": [
        "A_gpu@B_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[25.9445, 23.3451, 23.2453,  ..., 23.6876, 23.3642, 21.0127],\n",
              "        [29.1864, 29.7169, 27.8055,  ..., 29.9012, 26.9726, 24.5918],\n",
              "        [26.6460, 26.9354, 25.1543,  ..., 26.0435, 25.1616, 22.4802],\n",
              "        ...,\n",
              "        [29.2716, 27.0511, 27.1193,  ..., 28.7066, 26.1744, 24.4956],\n",
              "        [29.4815, 27.5012, 26.7596,  ..., 29.7794, 28.2612, 25.2685],\n",
              "        [26.5447, 23.0760, 24.2269,  ..., 26.3211, 23.7328, 21.0399]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sox7ng2OD-ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "56af008a-d8cc-4ba7-92ad-4ed1ada9e5d3"
      },
      "source": [
        "A@B_gpu #this won't work!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2e3381049b9a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mB_gpu\u001b[0m \u001b[0;31m#this won't work!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oi8M-GD-Zc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274326e2-77b4-4f49-fe79-19f7836decfe"
      },
      "source": [
        "C_gpu = A_gpu@B_gpu\n",
        "C = C_gpu.to(cpu)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[25.9445, 23.3451, 23.2453,  ..., 23.6876, 23.3642, 21.0127],\n",
              "        [29.1864, 29.7169, 27.8055,  ..., 29.9012, 26.9726, 24.5918],\n",
              "        [26.6460, 26.9354, 25.1543,  ..., 26.0435, 25.1616, 22.4802],\n",
              "        ...,\n",
              "        [29.2716, 27.0511, 27.1193,  ..., 28.7066, 26.1744, 24.4956],\n",
              "        [29.4815, 27.5012, 26.7596,  ..., 29.7794, 28.2612, 25.2685],\n",
              "        [26.5447, 23.0760, 24.2269,  ..., 26.3211, 23.7328, 21.0399]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vICVTE1wD-Zq"
      },
      "source": [
        "## Speedup from GPU\n",
        "`%%timeit` is a Jupyter Notebook magic command that is used to measure the execution time of a Python code snippet. When you add `%%timeit` at the beginning of a cell in a Jupyter Notebook, it will run the code in the cell multiple times and measure the average execution time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4raRnuw1D-Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132f1f9c-58bd-4790-c51f-644a172e5fb5"
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000,3000)\n",
        "B = torch.rand(3000,3000)\n",
        "for i in range(5):\n",
        "    B=torch.mm(A,B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.87 s ± 486 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch47eB6OD-Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf9063f-5680-4214-e4ff-f11f21417152"
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000,3000, device = gpu)\n",
        "B = torch.rand(3000,3000, device = gpu)\n",
        "for i in range(5):\n",
        "    B=torch.mm(A,B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68 ms ± 1.6 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDNQLaL6D-Zu"
      },
      "source": [
        "## Automatic Differentiation\n",
        "\n",
        "PyTorch uses dynamic computation graphs to compute the gradients of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r6mfgjHD-Zv"
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "w = torch.tensor([5.0], requires_grad = True)\n",
        "b = torch.tensor([2.0], requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezGUNqXD-Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563473e8-a007-47d6-9412-21ccb878132a"
      },
      "source": [
        "y = w*x + b #12 = 5*2 + 2\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Y_WzasD-Z0"
      },
      "source": [
        "Define an error for your function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7oYMHFD-Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8a2611-3095-4611-c651-7489889a3595"
      },
      "source": [
        "loss = torch.norm( y - 13)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<LinalgVectorNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuhWukrD-Z3"
      },
      "source": [
        "w.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMhtVXAhD-Z5"
      },
      "source": [
        "Calling `x.backward()` on any tensor forces pytorch to compute all the gradients of the tensors used to compute `x` which had the `requires_grad` flag set to `True`. The computed gradient will be stored in the `.grad` property of the tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PIU90uoD-Z5"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYbns6g4D-Z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4b6c88-fecc-4140-835d-929a2d710bab"
      },
      "source": [
        "w.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MYesARFD-Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0409fd-edb3-4ca1-d45f-bbdde6693a2c"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can tell PyTorch to skip the gradient calculations, which can help to reduce the memory usage and speed up computations."
      ],
      "metadata": {
        "id": "a9GBX-JwVykN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDhPOJHRD-aA"
      },
      "source": [
        "# It will reduce memory consumption for computations \n",
        "# that would otherwise have requires_grad=True\n",
        "with torch.no_grad(): #when we update w and b, do not update gradients\n",
        "    w -= 0.01 * w.grad\n",
        "    b -= 0.3 * b.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TlUBDHaD-aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bc8a1b-4ea9-4f30-978a-bf70261d72cc"
      },
      "source": [
        "w,b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5.0200], requires_grad=True), tensor([2.3000], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj85MTj2D-aF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f6f653-d10a-4165-d5c3-db45152250fb"
      },
      "source": [
        "w.grad, b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.]), tensor([-1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3UbDFA7D-aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc424cc6-be12-4f56-9450-33072d3c3618"
      },
      "source": [
        "# the gradients will accumulate and lead to incorrect updates and slower convergence.\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "w.grad, b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.]), tensor([0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgA5bqxD-aL"
      },
      "source": [
        "y = w*x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhEnrtmQD-aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e344e6b8-9fa4-4a54-b418-d1a589366563"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.3400], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJYE5aRpD-aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d18b83-29a7-4104-bb44-503ab6eb0b74"
      },
      "source": [
        "loss = torch.norm( y - 13)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6600, grad_fn=<LinalgVectorNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBLYqopxD-aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c07aea-3e51-459d-ca9e-d2907927d060"
      },
      "source": [
        "loss.backward()\n",
        "w.grad, b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.]), tensor([-1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNbj9oDlD-aS"
      },
      "source": [
        "### Making it more compact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlQ60VuqD-aS"
      },
      "source": [
        "def model_fn(x,w,b):\n",
        "    return w*x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zZHeiwJD-aV"
      },
      "source": [
        "def loss_fn(y,yt):\n",
        "    return torch.norm(y-yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7drmZAzD-aX"
      },
      "source": [
        "w = torch.tensor([5.0], requires_grad = True)\n",
        "b = torch.tensor([2.0], requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSogMXf-D-aY"
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "yt = torch.tensor([13.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BNsdU-D-aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2526d4-7465-4df5-eb6e-c5b373b49ef3"
      },
      "source": [
        "y = model_fn(x,w,b)\n",
        "loss = loss_fn(y,yt)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "    w -= 0.05 * w.grad\n",
        "    b -= 0.05 * b.grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print( f\" w = {w}\\n b = {b}\\n y = {y}\\n loss = {loss}\")\n",
        "#note that 'loss' indicates the loss for the previous m,c values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " w = tensor([5.5000], requires_grad=True)\n",
            " b = tensor([2.2500], requires_grad=True)\n",
            " y = tensor([13.0000], grad_fn=<AddBackward0>)\n",
            " loss = 9.5367431640625e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kRdaQe6D-ab"
      },
      "source": [
        "### Slightly more complicated problem"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Forward propagation to get predicted yhat\n",
        "2. Get the loss by loss_fun(y, yhat)\n",
        "3. Backward propagation to get the gradient\n",
        "4. Update parameters\n",
        "5. Repeat 1 ~ 4 until convergence"
      ],
      "metadata": {
        "id": "vNdBCLA1yTn4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alq94bPxD-ac"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdYDtWDD-ae"
      },
      "source": [
        "def model_fn(x,w,b):\n",
        "    return w@x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Cvos0BD-af"
      },
      "source": [
        "def loss_fn(y,yt):\n",
        "    return torch.norm(y-yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCjbW7HD-ah"
      },
      "source": [
        "w = torch.rand((5,5), requires_grad = True)\n",
        "b = torch.ones((5,1), requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsITRCClD-ai"
      },
      "source": [
        "x = torch.randn(5,100)\n",
        "yt = torch.randn(1,100)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFs5CphAD-al",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56de2ab6-68d9-43d2-b1be-550e9094e552"
      },
      "source": [
        "for i in range(50):\n",
        "  # 1. Forward\n",
        "  y = model_fn(x,w,b)\n",
        "  # 2. Get loss\n",
        "  loss = loss_fn(y,yt)\n",
        "  # 3. backward\n",
        "  loss.backward()\n",
        "  # 4. Update\n",
        "  with torch.no_grad():\n",
        "      w -= 0.05 * w.grad\n",
        "      b -= 0.05 * b.grad\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()\n",
        "\n",
        "  losses+=[loss.item()]\n",
        "  print( f\"loss = {loss}\")\n",
        "  plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 42.68125915527344\n",
            "loss = 38.598995208740234\n",
            "loss = 34.91118240356445\n",
            "loss = 31.68004035949707\n",
            "loss = 28.95591163635254\n",
            "loss = 26.76153564453125\n",
            "loss = 25.078950881958008\n",
            "loss = 23.84857177734375\n",
            "loss = 22.98369026184082\n",
            "loss = 22.392330169677734\n",
            "loss = 21.9942684173584\n",
            "loss = 21.727962493896484\n",
            "loss = 21.54981231689453\n",
            "loss = 21.43026351928711\n",
            "loss = 21.349693298339844\n",
            "loss = 21.29514503479004\n",
            "loss = 21.2580623626709\n",
            "loss = 21.232763290405273\n",
            "loss = 21.21544647216797\n",
            "loss = 21.203561782836914\n",
            "loss = 21.195388793945312\n",
            "loss = 21.18975067138672\n",
            "loss = 21.185855865478516\n",
            "loss = 21.183162689208984\n",
            "loss = 21.181293487548828\n",
            "loss = 21.179996490478516\n",
            "loss = 21.179094314575195\n",
            "loss = 21.178466796875\n",
            "loss = 21.178028106689453\n",
            "loss = 21.177722930908203\n",
            "loss = 21.177507400512695\n",
            "loss = 21.177358627319336\n",
            "loss = 21.17725372314453\n",
            "loss = 21.17717742919922\n",
            "loss = 21.177125930786133\n",
            "loss = 21.17708969116211\n",
            "loss = 21.17706298828125\n",
            "loss = 21.177047729492188\n",
            "loss = 21.177032470703125\n",
            "loss = 21.17702293395996\n",
            "loss = 21.177017211914062\n",
            "loss = 21.177011489868164\n",
            "loss = 21.17700958251953\n",
            "loss = 21.1770076751709\n",
            "loss = 21.177005767822266\n",
            "loss = 21.177003860473633\n",
            "loss = 21.177003860473633\n",
            "loss = 21.177003860473633\n",
            "loss = 21.177003860473633\n",
            "loss = 21.177001953125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvMUlEQVR4nO3de3iU5YH38d+TwySEZCbknJCEgyAUaFBQMW2lFFAWXYuVdtutXd3dXvrqoqvgouKhFE+h0mq1r2V78NKuSrHYouKWKgqkrwoUIymgEgURAjkRIJmcT/O8f0yIRDnkMDP3HL6f65qL5Jknkx+3SH48c9/3Y9m2bQsAACBAokwHAAAAkYXyAQAAAoryAQAAAoryAQAAAoryAQAAAoryAQAAAoryAQAAAoryAQAAAirGdIDP83g8qqioUFJSkizLMh0HAAD0gW3bamhoUE5OjqKiznxtI+jKR0VFhfLy8kzHAAAAA1BeXq7c3NwznhN05SMpKUmSN7zT6TScBgAA9IXb7VZeXl7Pz/EzCbryceKtFqfTSfkAACDE9GXKBBNOAQBAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQFE+AABAQAXdjeX85cHlS/ThuDwNbWvTr7+30HQcAAAiVsSUj9akeL2Z/BUN7zpkOgoAABEtYt52GVLfKEk6EpWuv731uuE0AABErogpHwVjJira7lS7Fac3Nr1mOg4AABErYsrHlf/0r0qzayVJrcmJhtMAABC5IqZ8SFJ6xzFJUr1rqOEkAABErsgqH631kqTaJK58AABgSkSVj9TGJklSbbzTcBIAACJXRJWP5BMrXmKHGU4CAEDkiqjyMeQYy20BADAtosrHRVO+qhi7Qx2WQxs2s9wWAAATIqp8XHrFt5RuH5EktSYnGU4DAEBkiqjyIX223LaO5bYAABgReeWjpUGSdJTltgAAGBFx5SO1sXvSKcttAQAwIuLKR3K9d6+PI7EphpMAABCZIq58xNV533Y5YqVr3ZrfGU4DAEDkibjycemMOYq129VlxWjnnl2m4wAAEHEirnxc9LXLlO7xLrdtSWHSKQAAgRZx5UOS0juOS5LqXJQPAAACLSLLR1qrW5J0NJG9PgAACLTILB8NJ5bbugwnAQAg8kRk+XCx3BYAAGMisnzE13mvfNRaaVr3h2fMhgEAIMJEZPmY/Y05ctht3uW2e983HQcAgIgSkeXj5OW2zcO4uy0AAIEUkeVDkjJO3N3WyYoXAAACKWLLx4m729ay3BYAgICK2PKR6u5e8cJyWwAAAipiy4ezvnuvj5hUw0kAAIgsEVs+Pltum6rnfv2Y4TQAAESOiC0f8755reLsVtlWtA4cqzIdBwCAiBGx5WPC+ecp48RyWxeTTgEACJSILR+SlN693PY45QMAgICJ6PKR1nxiuW2i4SQAAESOiC4fqQ3dy23jWG4LAECgRHT5cLHcFgCAgIvo8hFX573ycdRK0dO/WG44DQAAkSGiy8e8b16reLtZthWtiubjpuMAABARBlU+li9fLsuydNttt/Uca21t1YIFC5SamqrExETNnz9f1dXVg83pFycvt210MekUAIBAGHD52L59u371q1+poKCg1/GFCxdq3bp1WrNmjYqLi1VRUaGrr7560EH9JaPde8WD5bYAAATGgMpHY2OjrrnmGv3mN7/RsGHDeo7X19frqaee0qOPPqqZM2dq6tSpevrpp/XOO+9o69atPgvtSz3LbYdy5QMAgEAYUPlYsGCBrrjiCs2ePbvX8ZKSEnV0dPQ6Pn78eOXn52vLli2nfK22tja53e5ej0BK6V5uW8vdbQEACIiY/n7B6tWr9d5772n79u1feK6qqkoOh0PJycm9jmdmZqqq6tT3TykqKtKyZcv6G8NnXN03mKuJTjOWAQCASNKvKx/l5eW69dZb9fzzzys+Pt4nAZYsWaL6+vqeR3l5uU9et68cbu+Vj2NRqVq54r6Afm8AACJRv8pHSUmJampqNGXKFMXExCgmJkbFxcV64oknFBMTo8zMTLW3t6uurq7X11VXVysrK+uUrxkXFyen09nrEUjzvnmdEuzu/T7sjoB+bwAAIlG/ysesWbO0a9culZaW9jwuuOACXXPNNT0fx8bG6s033+z5mrKyMh08eFCFhYU+D+8LE84/T+ld3cttk5l0CgCAv/VrzkdSUpImTZrU69jQoUOVmprac/yHP/yhFi1apJSUFDmdTt1yyy0qLCzUxRdf7LvUPpbRflwHYkbquJPltgAA+Fu/J5yezWOPPaaoqCjNnz9fbW1tmjNnjn75y1/6+tv4VFpLo5TAclsAAAJh0OVj8+bNvT6Pj4/Xk08+qSeffHKwLx0wqe5GKVU6EpdsOgoAAGEvou/tckJS9w3muLstAAD+R/mQFOf27vVx3ErRL5bfYzgNAADhjfIh6a4f/1xDbe826+4oj+E0AACEN8pHt4yuWkmSexiTTgEA8CfKR7f0E3e3ZbktAAB+Rfnolt7snfdRm8CVDwAA/Iny0S2l+x4vLLcFAMC/KB/dkuq8E05rYri7LQAA/kT56BbX2CpJqreSteLB/zKcBgCA8EX56Hbn0keVZLslSa3xDsNpAAAIX5SPk5xYbtvgYtIpAAD+Qvk4SVp7nSTpmIvltgAA+Avl4yTpTd5Jpyy3BQDAfygfJ2G5LQAA/kf5OElSnXejsZpoltsCAOAvlI+TxLe2S5IaLJeWL7vNbBgAAMIU5eMki+/9qYbZxyRJbU7mfQAA4A+Uj8/J6qiRJNUNSzKcBACA8ET5+JzM1jpJUo2L8gEAgD9QPj4n3d19j5chLsNJAAAIT5SPz0k57l3xUh3LihcAAPyB8vE58ce9Vz6OWGn61RP3G04DAED4oXx8zrx512qo3SjbilZta4vpOAAAhB3Kx+dMOO88ZXV5V7zUpzDpFAAAX6N8nEJmq3evj9pk9voAAMDXKB+nkNF9g7nqBFa8AADga5SPUzix4qXKkWo4CQAA4YfycQqJR+slSTVRGdrw55fMhgEAIMxQPk7hwilfU6zdrg7Lob+Vvm06DgAAYYXycQqXXn6VsjzVkqRm7vECAIBPUT5OI7P9qCSplvIBAIBPUT5OI6PJLUmqSaR8AADgS5SP00ir677HS1yK4SQAAIQXysdpOI95r3xURWfqg9JSs2EAAAgjlI/TGJ6YKsvuUrM1VC+98j+m4wAAEDYoH6fxbwsWK92ulSS1MekUAACfoXycQVbHEUnSUcoHAAA+Q/k4g8xm706nR5IoHwAA+Arl4wzS3d03mItPNhsEAIAwQvk4g+RjTZKkqth0w0kAAAgflI8ziG/wlo86K0WPLFtkOA0AAOGB8nEGdyx9VMn2cUlSS1KC4TQAAIQHysdZZHXWSJLqUxINJwEAIDxQPs4is6VOknTEyYoXAAB8gfJxFukN3SteElyGkwAAEB4oH2eRetxbPljxAgCAb1A+ziKuu3wcsdL09JMrDKcBACD0UT7O4qpvXqshdrNsK1qHm46ajgMAQMijfJzFhPPOU1ZXtSTJzT1eAAAYNMpHH2S1HZMkHU2mfAAAMFiUjz7IaHRLkqqHOg0nAQAg9FE++iC1rlGSVO1INZwEAIDQR/nog6HHvFc+qqIytWH9S2bDAAAQ4igffXDReV9VrN2uDsuh7SVvmY4DAEBIo3z0waWXX6UMj/ceL42p7HQKAMBgUD76KLPdu8fHseShhpMAABDaKB99lNnsnfdRk8iKFwAABoPy0Udpdd03mIsfZjgJAAChjfLRR65j3TeYi87UB6WlZsMAABDCKB99lGrFyrI9arIS9fLL/2M6DgAAIYvy0Uc3Lb5faXatJKmVe7wAADBglI9+yOo4Ikk6NizRcBIAAEIX5aMfMlrqJUlHnFz5AABgoCgf/ZBR332Pl/hks0EAAAhhlI9+SD7eveIlJt1wEgAAQhflox/i3N4rH8ejUrXiwTsMpwEAIDRRPvrhrqWPyWnXSZJahjjMhgEAIET1q3ysXLlSBQUFcjqdcjqdKiws1Pr163uenzFjhizL6vW48cYbfR7apKxO7w3m6lJY8QIAwEDE9Ofk3NxcLV++XGPHjpVt2/rd736nefPmaceOHZo4caIk6frrr9f999/f8zUJCQm+TWxYZutxfRQr1bpY8QIAwED0q3xceeWVvT5/6KGHtHLlSm3durWnfCQkJCgrK8t3CYNMRkODlCRVD3GZjgIAQEga8JyPrq4urV69Wk1NTSosLOw5/vzzzystLU2TJk3SkiVL1NzcfMbXaWtrk9vt7vUIZil13kmnVY40w0kAAAhN/bryIUm7du1SYWGhWltblZiYqLVr12rChAmSpO9///saMWKEcnJytHPnTt15550qKyvTn/70p9O+XlFRkZYtWzbw30GADem+wdwRK13P/eZx/eD6Ww0nAgAgtFi2bdv9+YL29nYdPHhQ9fX1evHFF/Xb3/5WxcXFPQXkZBs3btSsWbO0d+9enXPOOad8vba2NrW1tfV87na7lZeXp/r6ejmdzn7+dvzvg9JSXX6sWa1Wgm7e9oLuvavIdCQAAIxzu91yuVx9+vnd77ddHA6HxowZo6lTp6qoqEiTJ0/W448/fspzp02bJknau3fvaV8vLi6uZ/XMiUcwm3DeecrpqpIk1acx6RQAgP4a9D4fHo+n15WLk5WWlkqSsrOzB/ttgkpOy1FJUvWw4C5KAAAEo37N+ViyZInmzp2r/Px8NTQ0aNWqVdq8ebNee+017du3T6tWrdLll1+u1NRU7dy5UwsXLtT06dNVUFDgr/xGZLvrpSSpYmiK6SgAAIScfpWPmpoaXXvttaqsrJTL5VJBQYFee+01XXrppSovL9cbb7yhn//852pqalJeXp7mz5+ve++911/ZjUmrrZeGS4cd4bukGAAAf+lX+XjqqadO+1xeXp6Ki4sHHSgUJDS0SpKOWyla/uNFuuvHjxpOBABA6ODeLgOw+L4VSvN4t1lvTmXSKQAA/UH5GKDc9mpJUm0qk04BAOgPyscAZTfVSZIqnWyzDgBAf1A+BijzmHcb+MPx6YaTAAAQWigfA5RUWy9JqozK1qt/XGU4DQAAoYPyMUCXzfgHxdst6rAcKt2703QcAABCBuVjgC78ykwN76qUJNWnMe8DAIC+onwMQk5LrSS2WQcAoD8oH4OQVe+d91GRMMxwEgAAQgflYxDSar0rXg6xzToAAH1G+RiExOZ2SVKdlaLlyxYaTgMAQGigfAzC7ff8ROnd26y3pDDvAwCAvqB8DNLw7m3Wa1jxAgBAn1A+Bimn8bgkqTKJ8gEAQF9QPgYp47h30mkF26wDANAnlI9BctbUSZIqorL1x+d+bTYMAAAhgPIxSJfOvFzxdrM6rVh9eGi/6TgAAAQ9yscg9dpmPZ0VLwAAnA3lwwdObLNexTbrAACcFeXDB7LruiedDk0xnAQAgOBH+fCB1KPee7wcjmWbdQAAzoby4QPOpk5Ztkd11jAV/XiR6TgAAAQ1yocPLLx3udLtI5KkljTmfQAAcCaUDx85sc36kVTKBwAAZ0L58JGcxjpJUoUz2WgOAACCHeXDRzKPda94iUsznAQAgOBG+fCRod3brFeyzToAAGdE+fCRq7/5LxpyYpv1w5+YjgMAQNCifPjIlyZP1vDOCklSXbrLcBoAAIIX5cOHclqPSpKqkikfAACcDuXDh7LrvDudVgwdZjgJAADBi/LhQ6m1DZKkw7HZhpMAABC8KB8+5GrrkmV7VG8lq2jZQtNxAAAISpQPH7p1ycPKsGskSc1pzPsAAOBUKB8+ltPuLR9HUthmHQCAU6F8+FhO43FJUiXbrAMAcEqUDx/LOHpim/V0w0kAAAhOlA8fc9Z2l4+obD3/2ycMpwEAIPhQPnzsqit/oAS7SV1WjD49Vmk6DgAAQYfy4WPebda9peN4GpNOAQD4PMqHH+S0eLdZrxzGclsAAD6P8uEHWfXd26wnpBhOAgBA8KF8+EFq96TTw7FZhpMAABB8KB9+4GrzyLI9clvJKlq2yHQcAACCCuXDD07eZr2JSacAAPRC+fCT3LZqSVJNWrLZIAAABBnKh5/kuY9Jkg46Uw0nAQAguFA+/CSr2ls+Po3L1Z6dOw2nAQAgeFA+/CS13VKU3aU6a5jWvvKM6TgAAAQNyoef3LL4fuV6DkuSjmfy1gsAACdQPvxoRLN3m/XDacMMJwEAIHhQPvwo71idJOnA0AyzQQAACCKUDz9K7Z50eiAmX39a9ZThNAAABAfKhx/NmT5XCXajOiyH3q/YZzoOAABBgfLhRxcUztDIjnJJUk0m8z4AAJAoH343oqFWknQwhRUvAABIlA+/yzlyXJJ0ID7bcBIAAIID5cPPkmq85aMqKls/WXa74TQAAJhH+fCzu5Y+pgyP9yZzDdzhFgAAykcgjGytkCRVZjDpFAAAykcA5NUdlSQdSEoznAQAAPMoHwGQWVUnSfrUkccdbgEAEY/yEQBjkrMUa7er0UrSH1991nQcAACMonwEwPd/eLPyug5Jko5npRhOAwCAWZSPABnZ5F3xUp7KpFMAQGSjfATI8NruzcYSsgwnAQDALMpHgCRXeu9wWx6dq1//3yLDaQAAMKdf5WPlypUqKCiQ0+mU0+lUYWGh1q9f3/N8a2urFixYoNTUVCUmJmr+/Pmqrq72eehQNH/etXLa9eqyYlTZ0WQ6DgAAxvSrfOTm5mr58uUqKSnRu+++q5kzZ2revHl6//33JUkLFy7UunXrtGbNGhUXF6uiokJXX321X4KHmvEFBRrZ7r3DbRWTTgEAESymPydfeeWVvT5/6KGHtHLlSm3dulW5ubl66qmntGrVKs2cOVOS9PTTT+tLX/qStm7dqosvvth3qUNUvvuodqZL5S7KBwAgcg14zkdXV5dWr16tpqYmFRYWqqSkRB0dHZo9e3bPOePHj1d+fr62bNnik7ChLqf7JnOfxg03nAQAAHP6XT527dqlxMRExcXF6cYbb9TatWs1YcIEVVVVyeFwKDk5udf5mZmZqqqqOu3rtbW1ye1293qEK2ddkyzbo9qodBUtW2Q6DgAARvS7fIwbN06lpaXatm2bbrrpJl133XX64IMPBhygqKhILper55GXlzfg1wp2/3XvCmV7KiVJ7kz2+wAARKZ+lw+Hw6ExY8Zo6tSpKioq0uTJk/X4448rKytL7e3tqqur63V+dXW1srJOv7fFkiVLVF9f3/MoLy/v928ilIxs8ZaPinTKBwAgMg16nw+Px6O2tjZNnTpVsbGxevPNN3ueKysr08GDB1VYWHjar4+Li+tZunviEc7yjnv3+ziQlG44CQAAZvRrtcuSJUs0d+5c5efnq6GhQatWrdLmzZv12muvyeVy6Yc//KEWLVqklJQUOZ1O3XLLLSosLGSly0nSq45LedKnMXna+No6zZxz5dm/CACAMNKv8lFTU6Nrr71WlZWVcrlcKigo0GuvvaZLL71UkvTYY48pKipK8+fPV1tbm+bMmaNf/vKXfgkeqs4f+2XF2a1qtRL0zg7KBwAg8li2bdumQ5zM7XbL5XKpvr4+bN+Cmf76Gn0UO1b/fOB1Pfavd5iOAwDAoPXn5zf3djFgRGONJO5wCwCITJQPA07c4Xb/kGzDSQAACDzKhwGuau+Kl4qobD328N2G0wAAEFiUDwOW3PeohnmOyraiVZcYazoOAAABRfkwZFT7IUlSJTudAgAiDOXDkPx671svB52phpMAABBYlA9DsrrnfeyPy9OenTsNpwEAIHAoH4aktluKsrtUbyVr7cu/Mx0HAICAoXwYcsvi+5XrOSxJOp6VYjgNAACBQ/kwaESz9w63h9MoHwCAyEH5MGjkEe+8j4+ShhtOAgBA4FA+DEo5dESSVB6dr6L7bzecBgCAwKB8GLRk6aPK7SqXJB3LYcktACAyUD4MG9fg3WxsX2aG4SQAAAQG5cOwURXeO9zuSRilsl27DKcBAMD/KB+GZTR2Ksbu0LGoVL34v8+ajgMAgN9RPgz7zzsf0OjO/ZKkylzeegEAhD/KRxAYd7xCkrQ3NdNwEgAA/I/yEQTyDtVKksriztGfX/694TQAAPgX5SMITC+4WEPtRrVYCdr+yfum4wAA4FeUjyAw49J/1Lltn0iSDjLvAwAQ5igfQWLskWpJ0keuHMNJAADwL8pHkMg66C0fn8SM1GMP32k4DQAA/kP5CBJ33/tTpXlq1GXFqHbYUNNxAADwG8pHEBnfdECS9El2uuEkAAD4D+UjiJxT7d1qvSwx33ASAAD8h/IRRFIrjsmyPaqIHq6HH1hoOg4AAH5B+Qgidyz9mfK7DkqSanPZ7RQAEJ4oH0FmnPuQJGlvBvt9AADCE+UjyIysOCJJKhsyWmW7dhlOAwCA71E+gszoOJccdpvqrWStWf+86TgAAPgc5SPI/OsNizSmw7vV+uE83noBAIQfykcQOvdYpSTp42FZhpMAAOB7lI8glFvunffxkWO0nvn1o4bTAADgW5SPIDR3+hw57Xq1W/Ha31pvOg4AAD5F+QhCUy+eoXEt3nkfB4az1ToAILxQPoLU2CPeu9yWOYcbTgIAgG9RPoJU2iHvvI9Po/P1k2W3G04DAIDvUD6C1N33/kzZngrZVrSOZ6eYjgMAgM9QPoLYuEbvfV72ZTHvAwAQPigfQWxUZfdW60NHGE4CAIDvUD6CWFqtW1F2l2qiMlX04GLTcQAA8AnKRxC7/d4VGtX1qSSpKp+3XgAA4YHyEeTG1R2WJH2clmk4CQAAvkH5CHIju7da/yB+rH71+AOG0wAAMHiUjyA3t3CmUj21arUS9EkC/7kAAKGPn2ZB7sLCb2hqfZkkaWdunuE0AAAMHuUjBIzbe0iStDtuvB55gFUvAIDQRvkIAd++/BrldB1Wh+VQZV6a6TgAAAwK5SMEjJs0SVOO7ZUklWaz4RgAILRRPkLEqL3eJbd7YsfqJ/cvNJwGAICBo3yEiHvufkSjOvfLtqJ18Jxc03EAABgwykcImVLziSRpR8Yow0kAABg4ykcIyd93SJbdpU9iRuvhB//LdBwAAAaE8hFC7vzRYxrf8bEkaf9Y3noBAIQmykeIOa/ygCSpJHWsynbvNpwGAID+o3yEmOzyWsXYHaqIHq4X//y86TgAAPQb5SPE3HHfCk1q2yNJKhvDWy8AgNBD+QhBBYcOSpJKXOfqvW1/NZwGAID+oXyEoDHNHsXbLToala51WzaYjgMAQL9QPkLQDbfep8ktH0qSPhjFWy8AgNBC+QhRX/60XJL0XtJ4rX95teE0AAD0HeUjRE1JzVeSXa8Gy6W3D5WZjgMAQJ9RPkLU1d/7N53f6F31smtknuE0AAD0HeUjhE385JAk6e9DvqRfP/6A4TQAAPQN5SOEXfmVS5XqqVWrNUT7EvhPCQAIDfzECmFTLpquqfXe+R5/z803nAYAgL6hfIS4cXu9b728HzdOjzyw2HAaAADOrl/lo6ioSBdeeKGSkpKUkZGhq666SmVlvVdazJgxQ5Zl9XrceOONPg2Nz3znih8op+uwOiyHKvPSTMcBAOCs+lU+iouLtWDBAm3dulUbNmxQR0eHLrvsMjU1NfU67/rrr1dlZWXP45FHHvFpaHzm3IkTNeXYXklSafYIw2kAADi7mP6c/Je//KXX588884wyMjJUUlKi6dOn9xxPSEhQVlaWbxLirEZ/VC6lS3tix+rhojt09xLKHgAgeA1qzkd9fb0kKSUlpdfx559/XmlpaZo0aZKWLFmi5ubm075GW1ub3G53rwf65+57f6ovt70v24rWu5PONR0HAIAzGnD58Hg8uu222/TVr35VkyZN6jn+/e9/X88995w2bdqkJUuW6Nlnn9UPfvCD075OUVGRXC5XzyMvjw2zBuJrH3rv9bJt6HkqenCR4TQAAJyeZdu2PZAvvOmmm7R+/Xq99dZbys09/c3NNm7cqFmzZmnv3r0655xzvvB8W1ub2traej53u93Ky8tTfX29nE7nQKJFrOmv/0EfxZ6rGfVbtfoqJvkCAALH7XbL5XL16ef3gK583HzzzXr11Ve1adOmMxYPSZo2bZokae/evad8Pi4uTk6ns9cDA/P1jz6QJL3jPF9Fy7j6AQAITv0qH7Zt6+abb9batWu1ceNGjRo16qxfU1paKknKzs4eUED03b984zsa2fmp2q04fThptOk4AACcUr/Kx4IFC/Tcc89p1apVSkpKUlVVlaqqqtTS0iJJ2rdvnx544AGVlJTo008/1SuvvKJrr71W06dPV0FBgV9+A/jMuRMnauYnuyVJ/2/YFDYdAwAEpX6Vj5UrV6q+vl4zZsxQdnZ2z+OFF16QJDkcDr3xxhu67LLLNH78eN1+++2aP3++1q1b55fw+KJvnz9dOV2H1WIl6KNxZ35LDAAAEwY84dRf+jNhBae2+KkiPTt6rhLtBv1nyQb95+L7TUcCAIQ5v084RXCbmT5K6Z4aNVpJ2jPcZToOAAC9UD7C0Nxvfk8zD5dKkjZmna9nf/OY2UAAAJyE8hGmLmiL1TD7mOqsFL0b12E6DgAAPSgfYepfrl+ob1TtkCRtHH6e1r+y2nAiAAC8KB9hbPzheiXZbh2JytDGI/tNxwEAQBLlI6z95+L79fVa79WPN0cU6L2//dVwIgAAKB9h79yyQxpiN6sierjW7KB8AADMo3yEuTvuW6FLjr8nSdo0epI+ev99w4kAAJGO8hEBvrT7EznsNn0aM1LPbl5jOg4AIMJRPiLAkqWP6itu79yP4rETDKcBAEQ6ykeEmLz7I0Xbnfoo9lzds5Lt1gEA5lA+IsSSex/V193bJUl/HHeJVjxwu+FEAIBIRfmIIDPKjyvLU6k6a5j+OmWS6TgAgAhF+YggN9xyt77197dl2V3annC+7vzNQ6YjAQAiEOUjwixd9KDmHN8iSfrjOdO1fBlvvwAAAovyEYH+oTlWuV3larSStHHa+fr4gw9MRwIARBDKRwT63r/8H33rvXcUbXdqZ9wkrdz2iulIAIAIQvmIUPfcUaTLj7wlSVo7YrqKHlxkOBEAIFJQPiLYtxOGa1TnfrVYCXr9wot4+wUAEBCUjwg258rv6B9Ltspht+lDx3g9UfK/piMBACIA5SPC3XPXT3Rlpfftl5eHX6KHHr7DcCIAQLijfEDXj7tI53Z8pHYrXn++cJr+uvEvpiMBAMIY5QM674JLNHf7dsXbLdoXc45W1XxoOhIAIIxRPiBJWnLPCl1V/v8kSa9mfE0P/PRuw4kAAOGK8oEeCy78R3257X11WrF6ZspcPfjIEtORAABhiPKBHmMnTNCc9/6uUZ371WQl6ZkLLqeAAAB8jvKBXv7r7kf0ne3bNKpzvxq7C8hDFBAAgA9RPvAFi+5erqv/tkUjOz/tLiBz9eBP7jIdCwAQJigfOKXF9zyi+X97RyM7P1WD5dTvLrycAgIA8AnKB07rRAEZcXIBeYQCAgAYHMoHzmjxPY/o29ve1ojOA94CcsFcPbicOSAAgIGjfOCsFt+7Qt/e9lZ3AXHpfy76B96CAQAMGOUDfXKigOR3HZDbcul/LpyrB1awERkAoP8oH+izxfeu0He2/FX5XQfltlz676lX6/oXfq4N//tH09EAACGE8oF+WXzfz/SdLcWa3LpbXVaM1mXM0I8cUXroJ3eajgYACBGWbdu26RAnc7vdcrlcqq+vl9PpNB0Hp7Fvzx79cstLWjviEjVbQxVrt+uK6rf0g8wv62szLzUdDwAQYP35+c2VDwzIOePH62f/dpeuf/tPmtj+oTosh17Kmqk7u9x66OHFpuMBAIIYVz4waPv27NEvtr2il/K+plYrQQ67Vd+sfEs3fOkrKpjyFdPxAAABwJUPBNQ548fr59fdoRve+aPGd5Sp3YrXizmzdUvtIa6CAAC+gCsf8Kmd772jX3/wjl7J+ZrarXhZdpfOb92ti/d8rB8tetB0PACAn/Tn5zflA37x0MOLtWnK+dodN6Hn2NiOvbpk/x59/6KZmnQ+b8cAQDihfCAodHlsLf/p3do+YYy2J0xWlxUjScr0VOnrh3dpSqNH//ofLNEFgHBA+UDQWf7A7fpg4mi9lTxZzVaiJCnJduuSY6Ua9+FB3XnfTw0nBAAMBuUDQesXK36kPTkuFWcVqDYqXZJk2R6N7tqviUcPasSBKv3zt36o0eeeazgpAKA/KB8Iehv//Cf95fAevTVyvD6JGd3ruQxPtSY1fKIx5VWaljdeV1z1z4ZSAgD6ivKB0GHbKnposSpGZumD9OEqix2jTiu25+kEu1ETWz7WuTXVSqk+pqvmflsTJ19kMDAA4FQoHwhZTzyyVBXJDpXlZGl3wlg1WL3/DAyxm5XfeUh5jbXKOVqn5Orj+ufv3qBRY8caSgwAkCgfCBNvb35Tb+zYrH0jsrQvKVsHo3PVYTm+cN5Qu1H5HYeU13RUqe5GOd3NGtLQpG9e+T1NKLjAQHIAiDyUD4SlTa//r94pfUu1Gck6lJKs8iGZOhQ9vNfbNCeLtduVZtcqreO40lrdSmlqUrK7WUMaWhTb0alvfOMfddFXvh7g3wUAhCfKByLGKy88o7+Xf6TajGRVJLt0NM6p2pgU1Vpp8ljRZ/xay+5Skhrk8jQoqatRSZ0tcra1KLGtTUPaOhTX2i5HW4ccbR2K7uiQM26orrj6Oo0YPfqMrwsAkYjygYi3+Y0/651tm9SSPFT1zqE6mjhUR+OTVBubLHeUUw1Kkm31/9ZGlt2lBLVoiN2sIXabHHa7HJ4OxXk65PB0ytHV6f21s1OOri7FdnYppqtL0R5bMZ1diu7yKLqzS1Ge7l+7PLK6bEV5PIqSR5YnWtExUlyUQ4lDk5SSkaWJkyZrzPgCP4wSAPgO5QM4i+KN67Vtyya1OWLUlhCn5qHxaox3qDE+Xm7HEDVHx6klKl4tUfFqtoaoWUNP+/ZOIFh2l6LlUZRO/Or9OEq2ouzPjlmyvb/a9mcfy1bUyZ93f2xJ3l97Pu8+1v1Xwolj3u//uc9lS7Z6XuOznCeeP8E+6ePPP//Za/f6vZ78ep8fCPvUn1inP+mLr3GK73lqZz/pVK89YEH1N7FvWYH+zVm+/C9z5teyrL58O0tR0We+EitJliPqrN8vISFBMTExZzwnPj5HQ4bknvGcMQnxum542lkz9QflA/Ax27a15tnf6tPyj9URY6nTEasOR4w6Y2PUGROt9pgYdcRGqz0mWh3RMWqLjlF7dIzao2LUaUWrMypaHVa0uqwYdVgx6lS0OqxYdVox6lCsuhT92cM6818sADBY30hJ0u8nn+PT1+zPz2/+lgP6wLIs/dO11wfkex06cEC7d21X5aGDamx2q6O9TR1dtmzLI0VJHtuSoix5uv+5ZUdHybYs7yNKsq0o2Za6j0l2VJT3moUlybLkiTpx3eGzY5+db0myP7suYsn7kCVZ3f84t7r/HWvps+sgJ/1jzbZOuq5x8scnOdNzJ79G72OfP3KKc85+yueuxZyaT/9F5tN/hQ9eUP1r0yCrL9etuv//ONs51lnOsSxL0We5WiFJVlz0WV8rISFBsbFnvgobHz9cQ4bknfGcUUO+uHIwkCgfQJDJHTFCuSNGmI4BAH7T/xl3AAAAg0D5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAAUX5AAAAARV0d7W1be8Nn91ut+EkAACgr0783D7xc/xMgq58NDQ0SJLy8vIMJwEAAP3V0NAgl8t1xnMsuy8VJYA8Ho8qKiqUlJQky7J8+tput1t5eXkqLy+X0+n06WvjixjvwGK8A4vxDizGO7AGMt62bauhoUE5OTmKijrzrI6gu/IRFRWl3Nxcv34Pp9PJH94AYrwDi/EOLMY7sBjvwOrveJ/tiscJTDgFAAABRfkAAAABFVHlIy4uTkuXLlVcXJzpKBGB8Q4sxjuwGO/AYrwDy9/jHXQTTgEAQHiLqCsfAADAPMoHAAAIKMoHAAAIKMoHAAAIqIgpH08++aRGjhyp+Ph4TZs2TX/7299MRwobf/3rX3XllVcqJydHlmXppZde6vW8bdv60Y9+pOzsbA0ZMkSzZ8/Wxx9/bCZsiCsqKtKFF16opKQkZWRk6KqrrlJZWVmvc1pbW7VgwQKlpqYqMTFR8+fPV3V1taHEoW3lypUqKCjo2WipsLBQ69ev73mesfav5cuXy7Is3XbbbT3HGHPf+fGPfyzLsno9xo8f3/O8P8c6IsrHCy+8oEWLFmnp0qV67733NHnyZM2ZM0c1NTWmo4WFpqYmTZ48WU8++eQpn3/kkUf0xBNP6L//+7+1bds2DR06VHPmzFFra2uAk4a+4uJiLViwQFu3btWGDRvU0dGhyy67TE1NTT3nLFy4UOvWrdOaNWtUXFysiooKXX311QZTh67c3FwtX75cJSUlevfddzVz5kzNmzdP77//viTG2p+2b9+uX/3qVyooKOh1nDH3rYkTJ6qysrLn8dZbb/U859extiPARRddZC9YsKDn866uLjsnJ8cuKioymCo8SbLXrl3b87nH47GzsrLsFStW9Byrq6uz4+Li7N///vcGEoaXmpoaW5JdXFxs27Z3bGNjY+01a9b0nPPhhx/akuwtW7aYihlWhg0bZv/2t79lrP2ooaHBHjt2rL1hwwb761//un3rrbfats2fb19bunSpPXny5FM+5++xDvsrH+3t7SopKdHs2bN7jkVFRWn27NnasmWLwWSRYf/+/aqqquo1/i6XS9OmTWP8faC+vl6SlJKSIkkqKSlRR0dHr/EeP3688vPzGe9B6urq0urVq9XU1KTCwkLG2o8WLFigK664otfYSvz59oePP/5YOTk5Gj16tK655hodPHhQkv/HOuhuLOdrtbW16urqUmZmZq/jmZmZ2rNnj6FUkaOqqkqSTjn+J57DwHg8Ht1222366le/qkmTJknyjrfD4VBycnKvcxnvgdu1a5cKCwvV2tqqxMRErV27VhMmTFBpaSlj7QerV6/We++9p+3bt3/hOf58+9a0adP0zDPPaNy4caqsrNSyZct0ySWXaPfu3X4f67AvH0C4WrBggXbv3t3rPVr43rhx41RaWqr6+nq9+OKLuu6661RcXGw6VlgqLy/Xrbfeqg0bNig+Pt50nLA3d+7cno8LCgo0bdo0jRgxQn/4wx80ZMgQv37vsH/bJS0tTdHR0V+YoVtdXa2srCxDqSLHiTFm/H3r5ptv1quvvqpNmzYpNze353hWVpba29tVV1fX63zGe+AcDofGjBmjqVOnqqioSJMnT9bjjz/OWPtBSUmJampqNGXKFMXExCgmJkbFxcV64oknFBMTo8zMTMbcj5KTk3Xuuedq7969fv/zHfblw+FwaOrUqXrzzTd7jnk8Hr355psqLCw0mCwyjBo1SllZWb3G3+12a9u2bYz/ANi2rZtvvllr167Vxo0bNWrUqF7PT506VbGxsb3Gu6ysTAcPHmS8fcTj8aitrY2x9oNZs2Zp165dKi0t7XlccMEFuuaaa3o+Zsz9p7GxUfv27VN2drb//3wPespqCFi9erUdFxdnP/PMM/YHH3xg33DDDXZycrJdVVVlOlpYaGhosHfs2GHv2LHDlmQ/+uij9o4dO+wDBw7Ytm3by5cvt5OTk+2XX37Z3rlzpz1v3jx71KhRdktLi+Hkoeemm26yXS6XvXnzZruysrLn0dzc3HPOjTfeaOfn59sbN2603333XbuwsNAuLCw0mDp03XXXXXZxcbG9f/9+e+fOnfZdd91lW5Zlv/7667ZtM9aBcPJqF9tmzH3p9ttvtzdv3mzv37/ffvvtt+3Zs2fbaWlpdk1NjW3b/h3riCgftm3bv/jFL+z8/Hzb4XDYF110kb1161bTkcLGpk2bbElfeFx33XW2bXuX29533312ZmamHRcXZ8+aNcsuKyszGzpEnWqcJdlPP/10zzktLS32f/zHf9jDhg2zExIS7G9961t2ZWWludAh7N///d/tESNG2A6Hw05PT7dnzZrVUzxsm7EOhM+XD8bcd7773e/a2dnZtsPhsIcPH25/97vftffu3dvzvD/H2rJt2x789RMAAIC+Cfs5HwAAILhQPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQEBRPgAAQED9fyLfKmR6/WZyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7iYj2eD-an"
      },
      "source": [
        "## Using Library functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xg-kywmD-an"
      },
      "source": [
        "model = torch.nn.Sequential( \n",
        "    # create layer of sequence\n",
        "    # F(WX + B)\n",
        "    # First layer: ReLU(WX + B)\n",
        "      # ReLU is important because it is doing some non-linear tranformation \n",
        "    torch.nn.Linear(5, 5),\n",
        "    torch.nn.ReLU(),\n",
        "\n",
        "    # Output layer\n",
        "    torch.nn.Linear(5, 1),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OocRUb9D-ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2059bc7-f824-4c5e-8331-d5b925ab02f5"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.2748, -0.2685, -0.0039,  0.1949,  0.3134],\n",
              "         [-0.1417,  0.2113, -0.4093, -0.3378, -0.0309],\n",
              "         [ 0.1067, -0.2863,  0.0161,  0.2390, -0.2557],\n",
              "         [-0.0025,  0.4096, -0.1420,  0.2324, -0.4004],\n",
              "         [ 0.3609,  0.1004, -0.3751, -0.0444, -0.1293]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1005,  0.1310, -0.1135,  0.3248,  0.0254], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.1023, -0.4273, -0.1353, -0.1554,  0.4187]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.3443], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgBOzYv5D-aq"
      },
      "source": [
        "#mean square loss → MSE = (1/n) * sum((y_pred - y_true)^2)\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bdGByKKD-as"
      },
      "source": [
        "x = torch.randn(100,5)\n",
        "yt = torch.randn(100,1)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KupJGFEFD-at"
      },
      "source": [
        "Using the optim package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ac8_-reD-au"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`optimizer.step()` is used to update the model parameters based on the gradients computed during backpropagation. During training, the optimizer computes the gradients of the loss function with respect to the model parameters\n",
        "  \n",
        "`optimizer.zero_grad()` is used to set the gradients of all the model parameters to zero before computing the gradients for the next batch of data. If we don't zero out the gradients before computing the gradients for the next batch, the gradients will accumulate, leading to incorrect updates and slower convergence."
      ],
      "metadata": {
        "id": "v1T-hdaSYBU7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtdxXUcRD-az",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b728033a-644f-4e68-b303-098bc4620a29"
      },
      "source": [
        "for i in range(1000):\n",
        "    y = model(x)\n",
        "    loss = loss_fn(y,yt)\n",
        "    loss.backward()\n",
        "\n",
        "    #make the parameter to take a step -> update the parameter\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses+=[loss.item()]\n",
        "    print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 109.11067199707031\n",
            "loss = 103.79290771484375\n",
            "loss = 100.48275756835938\n",
            "loss = 98.2297134399414\n",
            "loss = 96.45237731933594\n",
            "loss = 95.04127502441406\n",
            "loss = 93.97252655029297\n",
            "loss = 93.10059356689453\n",
            "loss = 92.59867858886719\n",
            "loss = 92.08340454101562\n",
            "loss = 91.49703979492188\n",
            "loss = 91.00679016113281\n",
            "loss = 90.61006927490234\n",
            "loss = 90.32628631591797\n",
            "loss = 90.17387390136719\n",
            "loss = 90.01512145996094\n",
            "loss = 89.75697326660156\n",
            "loss = 89.45178985595703\n",
            "loss = 89.17681121826172\n",
            "loss = 88.9458999633789\n",
            "loss = 88.77508544921875\n",
            "loss = 88.59017181396484\n",
            "loss = 88.42076873779297\n",
            "loss = 88.30952453613281\n",
            "loss = 88.15856170654297\n",
            "loss = 87.99110412597656\n",
            "loss = 87.78230285644531\n",
            "loss = 87.7010726928711\n",
            "loss = 87.61630249023438\n",
            "loss = 87.49898529052734\n",
            "loss = 87.36100769042969\n",
            "loss = 87.26129150390625\n",
            "loss = 87.2113037109375\n",
            "loss = 87.13215637207031\n",
            "loss = 87.03333282470703\n",
            "loss = 86.95282745361328\n",
            "loss = 86.86701965332031\n",
            "loss = 86.77272033691406\n",
            "loss = 86.68834686279297\n",
            "loss = 86.62247467041016\n",
            "loss = 86.55152893066406\n",
            "loss = 86.47868347167969\n",
            "loss = 86.42475891113281\n",
            "loss = 86.33193969726562\n",
            "loss = 86.2176513671875\n",
            "loss = 86.09074401855469\n",
            "loss = 85.93230438232422\n",
            "loss = 85.79592895507812\n",
            "loss = 85.65949249267578\n",
            "loss = 85.5207290649414\n",
            "loss = 85.38462829589844\n",
            "loss = 85.26136779785156\n",
            "loss = 85.13555908203125\n",
            "loss = 84.98519897460938\n",
            "loss = 84.84132385253906\n",
            "loss = 84.732421875\n",
            "loss = 84.57279205322266\n",
            "loss = 84.37320709228516\n",
            "loss = 84.00495147705078\n",
            "loss = 83.54967498779297\n",
            "loss = 83.1335220336914\n",
            "loss = 82.6943359375\n",
            "loss = 82.1092529296875\n",
            "loss = 81.6783676147461\n",
            "loss = 81.41060638427734\n",
            "loss = 81.19137573242188\n",
            "loss = 80.98468017578125\n",
            "loss = 80.81993865966797\n",
            "loss = 80.67147064208984\n",
            "loss = 80.51802062988281\n",
            "loss = 80.36338806152344\n",
            "loss = 80.16995239257812\n",
            "loss = 79.9708023071289\n",
            "loss = 79.75330352783203\n",
            "loss = 79.57772064208984\n",
            "loss = 79.38542175292969\n",
            "loss = 79.11942291259766\n",
            "loss = 78.83345794677734\n",
            "loss = 78.51482391357422\n",
            "loss = 78.11225891113281\n",
            "loss = 77.7218017578125\n",
            "loss = 77.35535430908203\n",
            "loss = 76.96784210205078\n",
            "loss = 76.58541870117188\n",
            "loss = 76.25736999511719\n",
            "loss = 75.99662017822266\n",
            "loss = 75.72188568115234\n",
            "loss = 75.43339538574219\n",
            "loss = 75.14974212646484\n",
            "loss = 74.87625122070312\n",
            "loss = 74.61064147949219\n",
            "loss = 74.28438568115234\n",
            "loss = 73.9139404296875\n",
            "loss = 73.51689910888672\n",
            "loss = 73.2157974243164\n",
            "loss = 72.94184875488281\n",
            "loss = 72.68424987792969\n",
            "loss = 72.36952209472656\n",
            "loss = 72.16139221191406\n",
            "loss = 71.937255859375\n",
            "loss = 71.64839935302734\n",
            "loss = 71.44383239746094\n",
            "loss = 71.17926025390625\n",
            "loss = 70.80870056152344\n",
            "loss = 70.38856506347656\n",
            "loss = 69.98352813720703\n",
            "loss = 69.74667358398438\n",
            "loss = 69.55352783203125\n",
            "loss = 69.3062744140625\n",
            "loss = 68.93001556396484\n",
            "loss = 68.56300354003906\n",
            "loss = 68.16690063476562\n",
            "loss = 67.78849029541016\n",
            "loss = 67.67294311523438\n",
            "loss = 67.66140747070312\n",
            "loss = 67.6174087524414\n",
            "loss = 67.59587860107422\n",
            "loss = 67.46672821044922\n",
            "loss = 67.25243377685547\n",
            "loss = 66.9552230834961\n",
            "loss = 66.78289031982422\n",
            "loss = 66.6868896484375\n",
            "loss = 66.54451751708984\n",
            "loss = 66.31571197509766\n",
            "loss = 66.17549133300781\n",
            "loss = 66.04360961914062\n",
            "loss = 65.9648208618164\n",
            "loss = 65.93440246582031\n",
            "loss = 65.82624816894531\n",
            "loss = 65.78388977050781\n",
            "loss = 65.82135009765625\n",
            "loss = 65.80817413330078\n",
            "loss = 65.61738586425781\n",
            "loss = 65.45295715332031\n",
            "loss = 65.51090240478516\n",
            "loss = 65.47335815429688\n",
            "loss = 65.34066772460938\n",
            "loss = 65.35551452636719\n",
            "loss = 65.23604583740234\n",
            "loss = 65.14596557617188\n",
            "loss = 65.12049865722656\n",
            "loss = 65.08979034423828\n",
            "loss = 65.01937103271484\n",
            "loss = 65.0317611694336\n",
            "loss = 65.0218505859375\n",
            "loss = 64.96424102783203\n",
            "loss = 64.942626953125\n",
            "loss = 64.85710144042969\n",
            "loss = 64.83378601074219\n",
            "loss = 64.80582427978516\n",
            "loss = 64.84246063232422\n",
            "loss = 64.77576446533203\n",
            "loss = 64.7625503540039\n",
            "loss = 64.77149963378906\n",
            "loss = 64.79930877685547\n",
            "loss = 64.76524353027344\n",
            "loss = 64.71095275878906\n",
            "loss = 64.70024871826172\n",
            "loss = 64.5920639038086\n",
            "loss = 64.62592315673828\n",
            "loss = 64.53827667236328\n",
            "loss = 64.572021484375\n",
            "loss = 64.5733642578125\n",
            "loss = 64.59600830078125\n",
            "loss = 64.50970458984375\n",
            "loss = 64.50718688964844\n",
            "loss = 64.4385986328125\n",
            "loss = 64.51167297363281\n",
            "loss = 64.4649658203125\n",
            "loss = 64.49008178710938\n",
            "loss = 64.43208312988281\n",
            "loss = 64.42103576660156\n",
            "loss = 64.37980651855469\n",
            "loss = 64.37522888183594\n",
            "loss = 64.3956298828125\n",
            "loss = 64.3296890258789\n",
            "loss = 64.35310363769531\n",
            "loss = 64.26229095458984\n",
            "loss = 64.2854995727539\n",
            "loss = 64.2760009765625\n",
            "loss = 64.25304412841797\n",
            "loss = 64.2459945678711\n",
            "loss = 64.19023895263672\n",
            "loss = 64.22769927978516\n",
            "loss = 64.17937469482422\n",
            "loss = 64.23748779296875\n",
            "loss = 64.1812744140625\n",
            "loss = 64.18716430664062\n",
            "loss = 64.16922760009766\n",
            "loss = 64.1513442993164\n",
            "loss = 64.08805084228516\n",
            "loss = 64.07969665527344\n",
            "loss = 64.06725311279297\n",
            "loss = 64.08061981201172\n",
            "loss = 64.07350158691406\n",
            "loss = 64.13275146484375\n",
            "loss = 64.27647399902344\n",
            "loss = 64.40010070800781\n",
            "loss = 64.38630676269531\n",
            "loss = 64.14958190917969\n",
            "loss = 63.94733810424805\n",
            "loss = 63.99652099609375\n",
            "loss = 64.1659927368164\n",
            "loss = 64.0995101928711\n",
            "loss = 63.9383430480957\n",
            "loss = 63.9859504699707\n",
            "loss = 64.09317016601562\n",
            "loss = 63.99589157104492\n",
            "loss = 63.914207458496094\n",
            "loss = 63.98004150390625\n",
            "loss = 64.01480102539062\n",
            "loss = 63.933677673339844\n",
            "loss = 63.894187927246094\n",
            "loss = 64.04401397705078\n",
            "loss = 63.97856903076172\n",
            "loss = 63.89643096923828\n",
            "loss = 63.92710876464844\n",
            "loss = 63.987525939941406\n",
            "loss = 63.89365768432617\n",
            "loss = 63.84131622314453\n",
            "loss = 63.89632797241211\n",
            "loss = 63.83222961425781\n",
            "loss = 63.88779830932617\n",
            "loss = 63.856937408447266\n",
            "loss = 63.87213897705078\n",
            "loss = 63.813636779785156\n",
            "loss = 63.784263610839844\n",
            "loss = 63.785011291503906\n",
            "loss = 63.80089569091797\n",
            "loss = 63.77534484863281\n",
            "loss = 63.769771575927734\n",
            "loss = 63.77781295776367\n",
            "loss = 63.78057098388672\n",
            "loss = 63.77027130126953\n",
            "loss = 63.75815200805664\n",
            "loss = 63.79547119140625\n",
            "loss = 63.743995666503906\n",
            "loss = 63.776065826416016\n",
            "loss = 63.7493782043457\n",
            "loss = 63.749351501464844\n",
            "loss = 63.79032897949219\n",
            "loss = 63.802757263183594\n",
            "loss = 63.766170501708984\n",
            "loss = 63.79609680175781\n",
            "loss = 63.77861404418945\n",
            "loss = 63.794708251953125\n",
            "loss = 63.74589538574219\n",
            "loss = 63.79408264160156\n",
            "loss = 63.748924255371094\n",
            "loss = 63.83769989013672\n",
            "loss = 63.7625617980957\n",
            "loss = 63.83518981933594\n",
            "loss = 63.707122802734375\n",
            "loss = 63.8084716796875\n",
            "loss = 63.71791076660156\n",
            "loss = 63.76933670043945\n",
            "loss = 63.70698928833008\n",
            "loss = 63.81767272949219\n",
            "loss = 63.71306610107422\n",
            "loss = 63.787322998046875\n",
            "loss = 63.70329284667969\n",
            "loss = 63.760929107666016\n",
            "loss = 63.73911666870117\n",
            "loss = 63.72275161743164\n",
            "loss = 63.66827392578125\n",
            "loss = 63.65753173828125\n",
            "loss = 63.670570373535156\n",
            "loss = 63.67361831665039\n",
            "loss = 63.652400970458984\n",
            "loss = 63.69664764404297\n",
            "loss = 63.651100158691406\n",
            "loss = 63.68899917602539\n",
            "loss = 63.69463348388672\n",
            "loss = 63.70944595336914\n",
            "loss = 63.68179702758789\n",
            "loss = 63.65705108642578\n",
            "loss = 63.668975830078125\n",
            "loss = 63.675132751464844\n",
            "loss = 63.66544723510742\n",
            "loss = 63.67243576049805\n",
            "loss = 63.64908218383789\n",
            "loss = 63.676483154296875\n",
            "loss = 63.67340850830078\n",
            "loss = 63.64016342163086\n",
            "loss = 63.651641845703125\n",
            "loss = 63.636878967285156\n",
            "loss = 63.689273834228516\n",
            "loss = 63.6363525390625\n",
            "loss = 63.69828796386719\n",
            "loss = 63.64458465576172\n",
            "loss = 63.67967224121094\n",
            "loss = 63.672157287597656\n",
            "loss = 63.65022277832031\n",
            "loss = 63.72953796386719\n",
            "loss = 63.71043395996094\n",
            "loss = 63.69187927246094\n",
            "loss = 63.662662506103516\n",
            "loss = 63.63920974731445\n",
            "loss = 63.686187744140625\n",
            "loss = 63.658416748046875\n",
            "loss = 63.63971710205078\n",
            "loss = 63.70060729980469\n",
            "loss = 63.729698181152344\n",
            "loss = 63.72830581665039\n",
            "loss = 63.656593322753906\n",
            "loss = 63.59681701660156\n",
            "loss = 63.6962890625\n",
            "loss = 63.64479064941406\n",
            "loss = 63.61974334716797\n",
            "loss = 63.597957611083984\n",
            "loss = 63.64710998535156\n",
            "loss = 63.63600158691406\n",
            "loss = 63.72089385986328\n",
            "loss = 63.694129943847656\n",
            "loss = 63.788692474365234\n",
            "loss = 63.75832748413086\n",
            "loss = 63.68983840942383\n",
            "loss = 63.6168212890625\n",
            "loss = 63.597938537597656\n",
            "loss = 63.59581756591797\n",
            "loss = 63.582275390625\n",
            "loss = 63.57834243774414\n",
            "loss = 63.56459045410156\n",
            "loss = 63.569664001464844\n",
            "loss = 63.583377838134766\n",
            "loss = 63.61133575439453\n",
            "loss = 63.6545524597168\n",
            "loss = 63.67273712158203\n",
            "loss = 63.64104080200195\n",
            "loss = 63.601402282714844\n",
            "loss = 63.56858444213867\n",
            "loss = 63.56098556518555\n",
            "loss = 63.59260559082031\n",
            "loss = 63.622840881347656\n",
            "loss = 63.67454528808594\n",
            "loss = 63.7099494934082\n",
            "loss = 63.683990478515625\n",
            "loss = 63.59221267700195\n",
            "loss = 63.540565490722656\n",
            "loss = 63.63105010986328\n",
            "loss = 63.67369079589844\n",
            "loss = 63.68804168701172\n",
            "loss = 63.617801666259766\n",
            "loss = 63.590518951416016\n",
            "loss = 63.60344314575195\n",
            "loss = 63.63302230834961\n",
            "loss = 63.56721878051758\n",
            "loss = 63.58201599121094\n",
            "loss = 63.58916091918945\n",
            "loss = 63.624935150146484\n",
            "loss = 63.61689758300781\n",
            "loss = 63.582820892333984\n",
            "loss = 63.60311508178711\n",
            "loss = 63.62621307373047\n",
            "loss = 63.57421112060547\n",
            "loss = 63.58831787109375\n",
            "loss = 63.70515441894531\n",
            "loss = 63.70490264892578\n",
            "loss = 63.66604232788086\n",
            "loss = 63.591400146484375\n",
            "loss = 63.562808990478516\n",
            "loss = 63.55784606933594\n",
            "loss = 63.614315032958984\n",
            "loss = 63.62138366699219\n",
            "loss = 63.552978515625\n",
            "loss = 63.545814514160156\n",
            "loss = 63.52956771850586\n",
            "loss = 63.534576416015625\n",
            "loss = 63.53823471069336\n",
            "loss = 63.50823974609375\n",
            "loss = 63.4820556640625\n",
            "loss = 63.5106201171875\n",
            "loss = 63.513607025146484\n",
            "loss = 63.507972717285156\n",
            "loss = 63.469032287597656\n",
            "loss = 63.503318786621094\n",
            "loss = 63.507591247558594\n",
            "loss = 63.509281158447266\n",
            "loss = 63.47877502441406\n",
            "loss = 63.472103118896484\n",
            "loss = 63.46432876586914\n",
            "loss = 63.49463653564453\n",
            "loss = 63.50654220581055\n",
            "loss = 63.4997673034668\n",
            "loss = 63.51970672607422\n",
            "loss = 63.509002685546875\n",
            "loss = 63.47724151611328\n",
            "loss = 63.46829605102539\n",
            "loss = 63.448028564453125\n",
            "loss = 63.452110290527344\n",
            "loss = 63.49710464477539\n",
            "loss = 63.501304626464844\n",
            "loss = 63.475101470947266\n",
            "loss = 63.467193603515625\n",
            "loss = 63.43065643310547\n",
            "loss = 63.429779052734375\n",
            "loss = 63.42131805419922\n",
            "loss = 63.42063903808594\n",
            "loss = 63.418827056884766\n",
            "loss = 63.40522384643555\n",
            "loss = 63.414398193359375\n",
            "loss = 63.39499282836914\n",
            "loss = 63.401939392089844\n",
            "loss = 63.39158630371094\n",
            "loss = 63.40167999267578\n",
            "loss = 63.40147399902344\n",
            "loss = 63.3985595703125\n",
            "loss = 63.41221237182617\n",
            "loss = 63.410179138183594\n",
            "loss = 63.40606689453125\n",
            "loss = 63.41648483276367\n",
            "loss = 63.41606903076172\n",
            "loss = 63.4305305480957\n",
            "loss = 63.416770935058594\n",
            "loss = 63.42140579223633\n",
            "loss = 63.4271240234375\n",
            "loss = 63.40825271606445\n",
            "loss = 63.42128372192383\n",
            "loss = 63.421085357666016\n",
            "loss = 63.397911071777344\n",
            "loss = 63.41112518310547\n",
            "loss = 63.410308837890625\n",
            "loss = 63.3902587890625\n",
            "loss = 63.407386779785156\n",
            "loss = 63.406951904296875\n",
            "loss = 63.43151092529297\n",
            "loss = 63.45729064941406\n",
            "loss = 63.466590881347656\n",
            "loss = 63.4619255065918\n",
            "loss = 63.474098205566406\n",
            "loss = 63.464508056640625\n",
            "loss = 63.444862365722656\n",
            "loss = 63.456451416015625\n",
            "loss = 63.43522262573242\n",
            "loss = 63.369293212890625\n",
            "loss = 63.37110900878906\n",
            "loss = 63.36903762817383\n",
            "loss = 63.35993576049805\n",
            "loss = 63.364891052246094\n",
            "loss = 63.358543395996094\n",
            "loss = 63.39177703857422\n",
            "loss = 63.388145446777344\n",
            "loss = 63.40863800048828\n",
            "loss = 63.387916564941406\n",
            "loss = 63.40278625488281\n",
            "loss = 63.385921478271484\n",
            "loss = 63.3526611328125\n",
            "loss = 63.35242462158203\n",
            "loss = 63.39403533935547\n",
            "loss = 63.387603759765625\n",
            "loss = 63.3701057434082\n",
            "loss = 63.37141036987305\n",
            "loss = 63.41486358642578\n",
            "loss = 63.43863296508789\n",
            "loss = 63.432861328125\n",
            "loss = 63.46961212158203\n",
            "loss = 63.532691955566406\n",
            "loss = 63.52959442138672\n",
            "loss = 63.52001190185547\n",
            "loss = 63.486045837402344\n",
            "loss = 63.43205642700195\n",
            "loss = 63.383026123046875\n",
            "loss = 63.3386344909668\n",
            "loss = 63.33389663696289\n",
            "loss = 63.38064193725586\n",
            "loss = 63.40068817138672\n",
            "loss = 63.41155242919922\n",
            "loss = 63.39352798461914\n",
            "loss = 63.39704895019531\n",
            "loss = 63.37726593017578\n",
            "loss = 63.33988571166992\n",
            "loss = 63.310821533203125\n",
            "loss = 63.33367919921875\n",
            "loss = 63.31768798828125\n",
            "loss = 63.312400817871094\n",
            "loss = 63.329376220703125\n",
            "loss = 63.320960998535156\n",
            "loss = 63.329856872558594\n",
            "loss = 63.32374572753906\n",
            "loss = 63.30952453613281\n",
            "loss = 63.34272384643555\n",
            "loss = 63.32881164550781\n",
            "loss = 63.31315612792969\n",
            "loss = 63.328155517578125\n",
            "loss = 63.32170486450195\n",
            "loss = 63.322574615478516\n",
            "loss = 63.319210052490234\n",
            "loss = 63.31138229370117\n",
            "loss = 63.36715316772461\n",
            "loss = 63.3697509765625\n",
            "loss = 63.36931610107422\n",
            "loss = 63.36619567871094\n",
            "loss = 63.38457489013672\n",
            "loss = 63.37004089355469\n",
            "loss = 63.339576721191406\n",
            "loss = 63.33789825439453\n",
            "loss = 63.35672378540039\n",
            "loss = 63.34330749511719\n",
            "loss = 63.312870025634766\n",
            "loss = 63.33138656616211\n",
            "loss = 63.321327209472656\n",
            "loss = 63.311004638671875\n",
            "loss = 63.29831314086914\n",
            "loss = 63.29076385498047\n",
            "loss = 63.314720153808594\n",
            "loss = 63.30340576171875\n",
            "loss = 63.281375885009766\n",
            "loss = 63.30769348144531\n",
            "loss = 63.312904357910156\n",
            "loss = 63.30253601074219\n",
            "loss = 63.30353927612305\n",
            "loss = 63.300811767578125\n",
            "loss = 63.3493766784668\n",
            "loss = 63.34957504272461\n",
            "loss = 63.387210845947266\n",
            "loss = 63.477901458740234\n",
            "loss = 63.54550552368164\n",
            "loss = 63.56903839111328\n",
            "loss = 63.50894546508789\n",
            "loss = 63.43368148803711\n",
            "loss = 63.37468719482422\n",
            "loss = 63.31425857543945\n",
            "loss = 63.28555679321289\n",
            "loss = 63.342491149902344\n",
            "loss = 63.372528076171875\n",
            "loss = 63.4044189453125\n",
            "loss = 63.39213180541992\n",
            "loss = 63.361839294433594\n",
            "loss = 63.3515739440918\n",
            "loss = 63.310115814208984\n",
            "loss = 63.28022766113281\n",
            "loss = 63.319461822509766\n",
            "loss = 63.331138610839844\n",
            "loss = 63.34031677246094\n",
            "loss = 63.31025314331055\n",
            "loss = 63.310115814208984\n",
            "loss = 63.308040618896484\n",
            "loss = 63.29926300048828\n",
            "loss = 63.27985382080078\n",
            "loss = 63.3090934753418\n",
            "loss = 63.321407318115234\n",
            "loss = 63.35499572753906\n",
            "loss = 63.34818649291992\n",
            "loss = 63.33659362792969\n",
            "loss = 63.303077697753906\n",
            "loss = 63.292572021484375\n",
            "loss = 63.281070709228516\n",
            "loss = 63.314353942871094\n",
            "loss = 63.3292236328125\n",
            "loss = 63.346580505371094\n",
            "loss = 63.3824348449707\n",
            "loss = 63.3662109375\n",
            "loss = 63.34804916381836\n",
            "loss = 63.3242301940918\n",
            "loss = 63.26821517944336\n",
            "loss = 63.291587829589844\n",
            "loss = 63.32398986816406\n",
            "loss = 63.313377380371094\n",
            "loss = 63.30731201171875\n",
            "loss = 63.276458740234375\n",
            "loss = 63.3076171875\n",
            "loss = 63.31817626953125\n",
            "loss = 63.2823486328125\n",
            "loss = 63.28803253173828\n",
            "loss = 63.319091796875\n",
            "loss = 63.28043746948242\n",
            "loss = 63.27638244628906\n",
            "loss = 63.28266143798828\n",
            "loss = 63.28493118286133\n",
            "loss = 63.285247802734375\n",
            "loss = 63.31010437011719\n",
            "loss = 63.290557861328125\n",
            "loss = 63.332977294921875\n",
            "loss = 63.32002258300781\n",
            "loss = 63.33489227294922\n",
            "loss = 63.316707611083984\n",
            "loss = 63.29790115356445\n",
            "loss = 63.306724548339844\n",
            "loss = 63.284629821777344\n",
            "loss = 63.28173828125\n",
            "loss = 63.292293548583984\n",
            "loss = 63.2799186706543\n",
            "loss = 63.275665283203125\n",
            "loss = 63.254241943359375\n",
            "loss = 63.277259826660156\n",
            "loss = 63.288753509521484\n",
            "loss = 63.29215621948242\n",
            "loss = 63.30119705200195\n",
            "loss = 63.29481506347656\n",
            "loss = 63.2606201171875\n",
            "loss = 63.26189041137695\n",
            "loss = 63.253684997558594\n",
            "loss = 63.291866302490234\n",
            "loss = 63.28357696533203\n",
            "loss = 63.330848693847656\n",
            "loss = 63.37847900390625\n",
            "loss = 63.39012908935547\n",
            "loss = 63.36967849731445\n",
            "loss = 63.353294372558594\n",
            "loss = 63.341575622558594\n",
            "loss = 63.32883834838867\n",
            "loss = 63.28656768798828\n",
            "loss = 63.2937126159668\n",
            "loss = 63.28942108154297\n",
            "loss = 63.27228546142578\n",
            "loss = 63.265926361083984\n",
            "loss = 63.26646041870117\n",
            "loss = 63.27476119995117\n",
            "loss = 63.26070022583008\n",
            "loss = 63.26856994628906\n",
            "loss = 63.28213882446289\n",
            "loss = 63.25794219970703\n",
            "loss = 63.284400939941406\n",
            "loss = 63.26294708251953\n",
            "loss = 63.247711181640625\n",
            "loss = 63.25129699707031\n",
            "loss = 63.2432746887207\n",
            "loss = 63.23728561401367\n",
            "loss = 63.25468444824219\n",
            "loss = 63.29338836669922\n",
            "loss = 63.33928298950195\n",
            "loss = 63.36152648925781\n",
            "loss = 63.408660888671875\n",
            "loss = 63.41714096069336\n",
            "loss = 63.42923355102539\n",
            "loss = 63.389225006103516\n",
            "loss = 63.313011169433594\n",
            "loss = 63.2852668762207\n",
            "loss = 63.27573776245117\n",
            "loss = 63.26546859741211\n",
            "loss = 63.257728576660156\n",
            "loss = 63.2999267578125\n",
            "loss = 63.375648498535156\n",
            "loss = 63.37670135498047\n",
            "loss = 63.33384704589844\n",
            "loss = 63.29387664794922\n",
            "loss = 63.2365608215332\n",
            "loss = 63.22208023071289\n",
            "loss = 63.25621032714844\n",
            "loss = 63.3443603515625\n",
            "loss = 63.4222412109375\n",
            "loss = 63.44636535644531\n",
            "loss = 63.395042419433594\n",
            "loss = 63.2911491394043\n",
            "loss = 63.27197265625\n",
            "loss = 63.258628845214844\n",
            "loss = 63.258216857910156\n",
            "loss = 63.33549499511719\n",
            "loss = 63.36231231689453\n",
            "loss = 63.3818244934082\n",
            "loss = 63.29823684692383\n",
            "loss = 63.24040603637695\n",
            "loss = 63.23158645629883\n",
            "loss = 63.23478317260742\n",
            "loss = 63.274662017822266\n",
            "loss = 63.28208923339844\n",
            "loss = 63.275367736816406\n",
            "loss = 63.24456024169922\n",
            "loss = 63.21654510498047\n",
            "loss = 63.22322082519531\n",
            "loss = 63.20713806152344\n",
            "loss = 63.22319030761719\n",
            "loss = 63.23414611816406\n",
            "loss = 63.237342834472656\n",
            "loss = 63.22011184692383\n",
            "loss = 63.24102783203125\n",
            "loss = 63.216636657714844\n",
            "loss = 63.210933685302734\n",
            "loss = 63.209259033203125\n",
            "loss = 63.220680236816406\n",
            "loss = 63.204978942871094\n",
            "loss = 63.23396301269531\n",
            "loss = 63.219970703125\n",
            "loss = 63.239295959472656\n",
            "loss = 63.279632568359375\n",
            "loss = 63.24812316894531\n",
            "loss = 63.24909210205078\n",
            "loss = 63.23854446411133\n",
            "loss = 63.22700500488281\n",
            "loss = 63.21141052246094\n",
            "loss = 63.20545959472656\n",
            "loss = 63.21916580200195\n",
            "loss = 63.2064208984375\n",
            "loss = 63.24469757080078\n",
            "loss = 63.23377990722656\n",
            "loss = 63.24890899658203\n",
            "loss = 63.244468688964844\n",
            "loss = 63.22632598876953\n",
            "loss = 63.21156311035156\n",
            "loss = 63.20777130126953\n",
            "loss = 63.19365310668945\n",
            "loss = 63.23768615722656\n",
            "loss = 63.27277374267578\n",
            "loss = 63.2734375\n",
            "loss = 63.32268524169922\n",
            "loss = 63.325050354003906\n",
            "loss = 63.2940673828125\n",
            "loss = 63.251495361328125\n",
            "loss = 63.22452163696289\n",
            "loss = 63.21561813354492\n",
            "loss = 63.19947052001953\n",
            "loss = 63.222328186035156\n",
            "loss = 63.22369384765625\n",
            "loss = 63.21896743774414\n",
            "loss = 63.22370910644531\n",
            "loss = 63.224063873291016\n",
            "loss = 63.19591522216797\n",
            "loss = 63.19400405883789\n",
            "loss = 63.23423385620117\n",
            "loss = 63.205902099609375\n",
            "loss = 63.20832824707031\n",
            "loss = 63.249046325683594\n",
            "loss = 63.246788024902344\n",
            "loss = 63.223785400390625\n",
            "loss = 63.22328186035156\n",
            "loss = 63.25214767456055\n",
            "loss = 63.244564056396484\n",
            "loss = 63.21813201904297\n",
            "loss = 63.20597839355469\n",
            "loss = 63.235809326171875\n",
            "loss = 63.226924896240234\n",
            "loss = 63.2113151550293\n",
            "loss = 63.1949462890625\n",
            "loss = 63.24311447143555\n",
            "loss = 63.246864318847656\n",
            "loss = 63.21769714355469\n",
            "loss = 63.19574737548828\n",
            "loss = 63.224124908447266\n",
            "loss = 63.23762512207031\n",
            "loss = 63.24321746826172\n",
            "loss = 63.1948127746582\n",
            "loss = 63.24321365356445\n",
            "loss = 63.26171112060547\n",
            "loss = 63.25928497314453\n",
            "loss = 63.25719451904297\n",
            "loss = 63.303077697753906\n",
            "loss = 63.29396057128906\n",
            "loss = 63.285301208496094\n",
            "loss = 63.24042510986328\n",
            "loss = 63.274871826171875\n",
            "loss = 63.25952911376953\n",
            "loss = 63.23590850830078\n",
            "loss = 63.234642028808594\n",
            "loss = 63.255332946777344\n",
            "loss = 63.23244857788086\n",
            "loss = 63.210960388183594\n",
            "loss = 63.183998107910156\n",
            "loss = 63.220462799072266\n",
            "loss = 63.21277618408203\n",
            "loss = 63.21935272216797\n",
            "loss = 63.26519775390625\n",
            "loss = 63.2972297668457\n",
            "loss = 63.30362319946289\n",
            "loss = 63.339481353759766\n",
            "loss = 63.30986785888672\n",
            "loss = 63.296443939208984\n",
            "loss = 63.29497528076172\n",
            "loss = 63.285362243652344\n",
            "loss = 63.275672912597656\n",
            "loss = 63.23600769042969\n",
            "loss = 63.196834564208984\n",
            "loss = 63.17247772216797\n",
            "loss = 63.19341278076172\n",
            "loss = 63.234230041503906\n",
            "loss = 63.258140563964844\n",
            "loss = 63.282569885253906\n",
            "loss = 63.29728698730469\n",
            "loss = 63.28558349609375\n",
            "loss = 63.24345397949219\n",
            "loss = 63.21433639526367\n",
            "loss = 63.25018310546875\n",
            "loss = 63.19413375854492\n",
            "loss = 63.209205627441406\n",
            "loss = 63.217430114746094\n",
            "loss = 63.20297622680664\n",
            "loss = 63.19950866699219\n",
            "loss = 63.190773010253906\n",
            "loss = 63.209205627441406\n",
            "loss = 63.20196533203125\n",
            "loss = 63.20317459106445\n",
            "loss = 63.21436309814453\n",
            "loss = 63.18315505981445\n",
            "loss = 63.179473876953125\n",
            "loss = 63.186737060546875\n",
            "loss = 63.19316101074219\n",
            "loss = 63.17823791503906\n",
            "loss = 63.22101593017578\n",
            "loss = 63.24671173095703\n",
            "loss = 63.23832702636719\n",
            "loss = 63.254371643066406\n",
            "loss = 63.25328063964844\n",
            "loss = 63.188743591308594\n",
            "loss = 63.16886901855469\n",
            "loss = 63.15308380126953\n",
            "loss = 63.196781158447266\n",
            "loss = 63.1993293762207\n",
            "loss = 63.23676681518555\n",
            "loss = 63.318355560302734\n",
            "loss = 63.351417541503906\n",
            "loss = 63.353057861328125\n",
            "loss = 63.34247589111328\n",
            "loss = 63.263145446777344\n",
            "loss = 63.208614349365234\n",
            "loss = 63.19761657714844\n",
            "loss = 63.18242645263672\n",
            "loss = 63.21046447753906\n",
            "loss = 63.24922561645508\n",
            "loss = 63.289710998535156\n",
            "loss = 63.28596878051758\n",
            "loss = 63.25230407714844\n",
            "loss = 63.30462646484375\n",
            "loss = 63.250587463378906\n",
            "loss = 63.192237854003906\n",
            "loss = 63.205413818359375\n",
            "loss = 63.17781448364258\n",
            "loss = 63.209197998046875\n",
            "loss = 63.25286865234375\n",
            "loss = 63.26600646972656\n",
            "loss = 63.317115783691406\n",
            "loss = 63.27212905883789\n",
            "loss = 63.22292709350586\n",
            "loss = 63.20020294189453\n",
            "loss = 63.15828323364258\n",
            "loss = 63.18534469604492\n",
            "loss = 63.20574951171875\n",
            "loss = 63.27211380004883\n",
            "loss = 63.329010009765625\n",
            "loss = 63.305519104003906\n",
            "loss = 63.249549865722656\n",
            "loss = 63.1949348449707\n",
            "loss = 63.17819595336914\n",
            "loss = 63.18857192993164\n",
            "loss = 63.161712646484375\n",
            "loss = 63.185089111328125\n",
            "loss = 63.222625732421875\n",
            "loss = 63.19649887084961\n",
            "loss = 63.18826675415039\n",
            "loss = 63.176082611083984\n",
            "loss = 63.16785430908203\n",
            "loss = 63.16163635253906\n",
            "loss = 63.15589904785156\n",
            "loss = 63.17060089111328\n",
            "loss = 63.223907470703125\n",
            "loss = 63.18402862548828\n",
            "loss = 63.18236541748047\n",
            "loss = 63.1913948059082\n",
            "loss = 63.174076080322266\n",
            "loss = 63.16344451904297\n",
            "loss = 63.18372344970703\n",
            "loss = 63.175567626953125\n",
            "loss = 63.166587829589844\n",
            "loss = 63.16965103149414\n",
            "loss = 63.188724517822266\n",
            "loss = 63.184940338134766\n",
            "loss = 63.172176361083984\n",
            "loss = 63.14820861816406\n",
            "loss = 63.141639709472656\n",
            "loss = 63.16425323486328\n",
            "loss = 63.17079162597656\n",
            "loss = 63.183143615722656\n",
            "loss = 63.17402648925781\n",
            "loss = 63.22319412231445\n",
            "loss = 63.220672607421875\n",
            "loss = 63.23176574707031\n",
            "loss = 63.23854064941406\n",
            "loss = 63.2119140625\n",
            "loss = 63.18278121948242\n",
            "loss = 63.14635467529297\n",
            "loss = 63.153053283691406\n",
            "loss = 63.175254821777344\n",
            "loss = 63.217613220214844\n",
            "loss = 63.30119323730469\n",
            "loss = 63.37318801879883\n",
            "loss = 63.391700744628906\n",
            "loss = 63.36675262451172\n",
            "loss = 63.249698638916016\n",
            "loss = 63.159114837646484\n",
            "loss = 63.141845703125\n",
            "loss = 63.197105407714844\n",
            "loss = 63.19165802001953\n",
            "loss = 63.257083892822266\n",
            "loss = 63.2354736328125\n",
            "loss = 63.24979782104492\n",
            "loss = 63.21055603027344\n",
            "loss = 63.160606384277344\n",
            "loss = 63.172576904296875\n",
            "loss = 63.19127655029297\n",
            "loss = 63.22673797607422\n",
            "loss = 63.19866943359375\n",
            "loss = 63.18853759765625\n",
            "loss = 63.2255744934082\n",
            "loss = 63.18912887573242\n",
            "loss = 63.16636276245117\n",
            "loss = 63.16809844970703\n",
            "loss = 63.17254638671875\n",
            "loss = 63.1832160949707\n",
            "loss = 63.16232681274414\n",
            "loss = 63.13944625854492\n",
            "loss = 63.147544860839844\n",
            "loss = 63.162967681884766\n",
            "loss = 63.15951919555664\n",
            "loss = 63.16825866699219\n",
            "loss = 63.158565521240234\n",
            "loss = 63.162227630615234\n",
            "loss = 63.183353424072266\n",
            "loss = 63.20757293701172\n",
            "loss = 63.167938232421875\n",
            "loss = 63.196537017822266\n",
            "loss = 63.180904388427734\n",
            "loss = 63.161956787109375\n",
            "loss = 63.19407653808594\n",
            "loss = 63.190673828125\n",
            "loss = 63.191341400146484\n",
            "loss = 63.148597717285156\n",
            "loss = 63.19944763183594\n",
            "loss = 63.14543151855469\n",
            "loss = 63.186866760253906\n",
            "loss = 63.1735954284668\n",
            "loss = 63.16900634765625\n",
            "loss = 63.19573211669922\n",
            "loss = 63.153587341308594\n",
            "loss = 63.17292022705078\n",
            "loss = 63.15151596069336\n",
            "loss = 63.16099548339844\n",
            "loss = 63.156883239746094\n",
            "loss = 63.173797607421875\n",
            "loss = 63.18090057373047\n",
            "loss = 63.14418029785156\n",
            "loss = 63.17414474487305\n",
            "loss = 63.146453857421875\n",
            "loss = 63.15985107421875\n",
            "loss = 63.141639709472656\n",
            "loss = 63.17049026489258\n",
            "loss = 63.163570404052734\n",
            "loss = 63.165348052978516\n",
            "loss = 63.16017532348633\n",
            "loss = 63.15178680419922\n",
            "loss = 63.203887939453125\n",
            "loss = 63.14009094238281\n",
            "loss = 63.189178466796875\n",
            "loss = 63.18056869506836\n",
            "loss = 63.2218017578125\n",
            "loss = 63.16382598876953\n",
            "loss = 63.183006286621094\n",
            "loss = 63.18071746826172\n",
            "loss = 63.1800537109375\n",
            "loss = 63.169769287109375\n",
            "loss = 63.17475891113281\n",
            "loss = 63.18062973022461\n",
            "loss = 63.17813491821289\n",
            "loss = 63.20037078857422\n",
            "loss = 63.15057373046875\n",
            "loss = 63.13581848144531\n",
            "loss = 63.184295654296875\n",
            "loss = 63.17725372314453\n",
            "loss = 63.15418243408203\n",
            "loss = 63.153953552246094\n",
            "loss = 63.16200256347656\n",
            "loss = 63.152488708496094\n",
            "loss = 63.166229248046875\n",
            "loss = 63.16795349121094\n",
            "loss = 63.187259674072266\n",
            "loss = 63.21139907836914\n",
            "loss = 63.25666809082031\n",
            "loss = 63.33526611328125\n",
            "loss = 63.406192779541016\n",
            "loss = 63.503326416015625\n",
            "loss = 63.60026550292969\n",
            "loss = 63.68192672729492\n",
            "loss = 63.74825668334961\n",
            "loss = 63.68777084350586\n",
            "loss = 63.477760314941406\n",
            "loss = 63.266746520996094\n",
            "loss = 63.17491912841797\n",
            "loss = 63.250572204589844\n",
            "loss = 63.377899169921875\n",
            "loss = 63.41619110107422\n",
            "loss = 63.423763275146484\n",
            "loss = 63.29020690917969\n",
            "loss = 63.153785705566406\n",
            "loss = 63.149749755859375\n",
            "loss = 63.2224006652832\n",
            "loss = 63.260807037353516\n",
            "loss = 63.277103424072266\n",
            "loss = 63.212196350097656\n",
            "loss = 63.16851043701172\n",
            "loss = 63.162662506103516\n",
            "loss = 63.17155456542969\n",
            "loss = 63.183692932128906\n",
            "loss = 63.19300842285156\n",
            "loss = 63.159034729003906\n",
            "loss = 63.14575958251953\n",
            "loss = 63.13886260986328\n",
            "loss = 63.122039794921875\n",
            "loss = 63.159912109375\n",
            "loss = 63.17894744873047\n",
            "loss = 63.163421630859375\n",
            "loss = 63.14356231689453\n",
            "loss = 63.13752746582031\n",
            "loss = 63.17144012451172\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRlkcpT0D-a1"
      },
      "source": [
        "## MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4GfdMRhD-a1"
      },
      "source": [
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyQ4gP46D-a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f272c746-a876-4fbc-f96d-5b3639759013"
      },
      "source": [
        "data = MNIST(\".\",download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 83862746.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 47860803.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 28057265.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3066236.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfX2XnGD-a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35663150-0e94-48b1-a315-5e181e5eca21"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7fwSvMkD-a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "938fdf60-4bc2-492e-eaff-2754810c6ce7"
      },
      "source": [
        "import numpy as np\n",
        "img,y = data[np.random.randint(1,60000)]\n",
        "print(y)\n",
        "img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F33C2B216C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABLklEQVR4nMXOwSsEURwH8K9pQ00btlkuok1oXCRxUQhHNw6klDPO68bmolwc2YvNP2DlIHtaSi5y2OKClAvbRCba3fJ9nsObnXmDM7/Le7/f571vP+B/K3om5Gr0d+t2SUG3M5gY3tl2PmSYH3uAebLgY8Sz/d66t+xBHEDz8n0+HLlGjgFozd3OJdPuSMhanhQCHVvvZM7ScZG8jKtrww3JI32hacBx1MCqB9CjYx9w6IXcPQqgcViLfSUH/CZFMhvYaFmIACeEEGLFj+2PSBk8zW9IqXoDAGpr9NWZOoa2ULrkLwgAZpOOz5/AUqxqsd1BPQjJEjlfbcZJXrdr+kA623YXLNveOSWLCf3r1BVJljMXJMnieigXky8VkhQkK4UEvtdsQeHmzA/6y/oCvKyBV14B4IMAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3giZTnRiD-a-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec9b749-455e-421b-b897-7f7e35c34d71"
      },
      "source": [
        "print(data.train_data[2].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsZHdAMlD-a_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7b3cc9-f6c9-4e53-afb6-33600ffbc13a"
      },
      "source": [
        "print(data.train_labels[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROmpaSMVD-bA"
      },
      "source": [
        "### MNIST Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHhKarpfD-bB"
      },
      "source": [
        "model = torch.nn.Sequential( # 28*28 = 784\n",
        "    torch.nn.Linear(784,  100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 10),\n",
        "    torch.nn.LogSoftmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Q59QCED-bC"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehneQZatD-bG"
      },
      "source": [
        "sample = np.random.choice(range(len(data.train_data)),1000)\n",
        "x = data.train_data[sample].reshape(1000,-1).float()/255\n",
        "yt = data.train_labels[sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucZS9UPAD-bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53d1d34-1d3b-4789-8d62-d75e0d80909a"
      },
      "source": [
        "x.shape,yt.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 784]), torch.Size([1000]))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdOxW-tYD-bK"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtNhgaED-bL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "5d08a86e-2898-4853-a814-31677d8e85d0"
      },
      "source": [
        "for i in range(100):\n",
        "    \n",
        "    sample = np.random.choice(range(len(data.train_data)),1000)\n",
        "    x = data.train_data[sample].reshape(1000,-1).float()/255\n",
        "    yt = data.train_labels[sample]\n",
        "    \n",
        "    y = model(x)\n",
        "\n",
        "    # input (Tensor) – Predicted unnormalized logits\n",
        "    # target (Tensor) – Ground truth class indices or class probabilities\n",
        "    loss = loss_fn(y,yt)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses+=[loss.item()]\n",
        "    #print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BAXeaKHD-bM"
      },
      "source": [
        "x_test = data.train_data[-1000:].reshape(1000,-1).float()/255\n",
        "y_test = data.train_labels[-1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VXFOBCjD-bO"
      },
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oG-bennMI3Y",
        "outputId": "1bb9ea9f-cb27-4e39-dd8e-9158b7c54fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -5.6633,  -9.4235,  -6.2136,  -9.4794,  -3.8566,  -6.2634,  -0.0299,\n",
              "         -8.7633,  -7.3443, -11.3133])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0c-JhpD-bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a8f7ec-3b70-4874-c2ac-2396b819b01b"
      },
      "source": [
        "print(\"Accuracy = \", (y_pred.argmax(dim=1) == y_test).sum().float().item()/1000.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6m7c0qD-bQ"
      },
      "source": [
        "## Course Conclusion\n",
        "\n",
        "1. By now you should have a sufficient introduction to the various ways one can use python for scientific computing. The best way to learn more is to start using python for whatever project you are working on. Only practice will make you comfortable with using python.   \n",
        "\n",
        "Recommended Project Source: kaggle  \n",
        "\n",
        "Recommended ML/DL Courses: CS229, 230, 231N, 224 series, 238, 246  \n",
        "\n",
        "2. I appreciate your time to submit the course feedback, which means a lot to me and improvement for this course in the future  \n",
        " \n"
      ]
    }
  ]
}